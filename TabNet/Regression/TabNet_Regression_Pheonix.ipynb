{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDBYSpdqvjM-",
        "outputId": "2d5064ee-b5be-4918-9c64-eb60799756cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 870 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.7.3)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.12.1+cu113)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR3iA6tQHZS9",
        "outputId": "08e7ba3a-cba5-4239-9bc7-67671ccfcd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=da7b5a43951080dc026d93036bd0904cd1ea755ee079e8ffb61c833fdeda503a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "import os\n",
        "import wget\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "tcnaUPm-HSTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "slqsvl2THeIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/drive/Shareddrives/Topgun/data_that_includes_everything.csv\"\n"
      ],
      "metadata": {
        "id": "HeNNiHV3HdpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and split"
      ],
      "metadata": {
        "id": "ej2ZVsVwKYtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(csv_path)\n",
        "if \"Set\" not in train.columns:\n",
        "    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
        "\n",
        "train_indices = train[train.Set==\"train\"].index\n",
        "valid_indices = train[train.Set==\"valid\"].index\n",
        "test_indices = train[train.Set==\"test\"].index\n"
      ],
      "metadata": {
        "id": "Bx-Uh-LwKar1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.dtypes)"
      ],
      "metadata": {
        "id": "ueTQMRnmNMGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple preprocessing. \n",
        "잘 모르겠음,, 데이터 타입이 달라서ㅜ"
      ],
      "metadata": {
        "id": "ZBTZiUXfLFE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fill the blank\n",
        "categorical_columns = []\n",
        "categorical_dims =  {}\n",
        "for col in train.columns[train.dtypes == object]:\n",
        "    print(col)\n",
        "    l_enc = LabelEncoder()\n",
        "    train[col] = train[col].fillna(\"VV_likely\")\n",
        "    train[col] = l_enc.fit_transform(train[col].values)\n",
        "    categorical_columns.append(col)\n",
        "    categorical_dims[col] = len(l_enc.classes_)\n",
        "\n",
        "for col in train.columns[train.dtypes == 'float64']:\n",
        "    train.fillna(train.loc[train_indices, col].mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "4PVC-ODpLE2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target= \"brix\"\n",
        "unused_feat = ['Set']\n",
        "\n",
        "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
        "\n",
        "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
        "\n",
        "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
        "\n",
        "# define your embedding sizes : here just a random choice\n",
        "cat_emb_dim = [5, 4, 3, 6, 2, 2, 1, 10]"
      ],
      "metadata": {
        "id": "Ve33bpwKRbkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network parameters"
      ],
      "metadata": {
        "id": "y-_vzG1MJ6lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetRegressor(cat_dims=cat_dims, cat_emb_dim=cat_emb_dim, cat_idxs=cat_idxs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P6iMFoBWxhC",
        "outputId": "f048c015-9c13-4a66-a593-e13c3908d27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "1H8WYj_w8a6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train[features].values[train_indices]\n",
        "y_train = train[target].values[train_indices].reshape(-1, 1)\n",
        "\n",
        "X_valid = train[features].values[valid_indices]\n",
        "y_valid = train[target].values[valid_indices].reshape(-1, 1)\n",
        "\n",
        "X_test = train[features].values[test_indices]\n",
        "y_test = train[target].values[test_indices].reshape(-1, 1)"
      ],
      "metadata": {
        "id": "PPeSKcQY8ZuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 210 if not os.getenv(\"CI\", False) else 2"
      ],
      "metadata": {
        "id": "OB338lmC8dwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
        "aug = RegressionSMOTE(p=0.2)"
      ],
      "metadata": {
        "id": "rGfmZ48u8gOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
        "    max_epochs=max_epochs,\n",
        "    patience=50,\n",
        "    batch_size=1024, virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    augmentations=aug, #aug\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLZBUbP8kN1",
        "outputId": "81a919b1-342e-436d-9d15-26489bca63bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 171.43321| train_rmsle: 3.78448 | train_mae: 26.12543| train_rmse: 31.68216| train_mse: 1003.75901| valid_rmsle: 3.33897 | valid_mae: 17.95264| valid_rmse: 19.53054| valid_mse: 381.44183|  0:00:00s\n",
            "epoch 1  | loss: 163.98494| train_rmsle: 0.90959 | train_mae: 12.56177| train_rmse: 20.35375| train_mse: 414.27509| valid_rmsle: 0.92762 | valid_mae: 16.06963| valid_rmse: 23.24836| valid_mse: 540.48633|  0:00:00s\n",
            "epoch 2  | loss: 159.25465| train_rmsle: 1.04825 | train_mae: 23.10796| train_rmse: 27.3676 | train_mse: 748.98543| valid_rmsle: 1.03637 | valid_mae: 24.21131| valid_rmse: 28.09023| valid_mse: 789.06119|  0:00:00s\n",
            "epoch 3  | loss: 150.5573| train_rmsle: 1.96948 | train_mae: 48.65606| train_rmse: 85.31156| train_mse: 7278.06294| valid_rmsle: 2.82306 | valid_mae: 76.89361| valid_rmse: 120.44354| valid_mse: 14506.64633|  0:00:00s\n",
            "epoch 4  | loss: 145.603 | train_rmsle: 1.97582 | train_mae: 49.48412| train_rmse: 87.18588| train_mse: 7601.37693| valid_rmsle: 1.54187 | valid_mae: 39.30601| valid_rmse: 71.19685| valid_mse: 5068.992|  0:00:00s\n",
            "epoch 5  | loss: 141.25908| train_rmsle: 2.71439 | train_mae: 74.39169| train_rmse: 119.79929| train_mse: 14351.86874| valid_rmsle: 2.58705 | valid_mae: 67.24555| valid_rmse: 104.36884| valid_mse: 10892.85451|  0:00:00s\n",
            "epoch 6  | loss: 134.09644| train_rmsle: 2.15343 | train_mae: 59.66123| train_rmse: 106.56215| train_mse: 11355.492| valid_rmsle: 1.88301 | valid_mae: 53.30288| valid_rmse: 101.30316| valid_mse: 10262.33106|  0:00:00s\n",
            "epoch 7  | loss: 125.38955| train_rmsle: 2.23187 | train_mae: 55.02167| train_rmse: 80.71683| train_mse: 6515.20622| valid_rmsle: 2.77592 | valid_mae: 65.68151| valid_rmse: 82.96045| valid_mse: 6882.43648|  0:00:00s\n",
            "epoch 8  | loss: 119.24798| train_rmsle: 2.1223  | train_mae: 50.8565 | train_rmse: 71.1074 | train_mse: 5056.26248| valid_rmsle: 2.35302 | valid_mae: 57.52075| valid_rmse: 77.34368| valid_mse: 5982.04533|  0:00:00s\n",
            "epoch 9  | loss: 111.90491| train_rmsle: 2.38738 | train_mae: 56.42645| train_rmse: 74.19033| train_mse: 5504.20479| valid_rmsle: 2.7394  | valid_mae: 63.21157| valid_rmse: 76.04528| valid_mse: 5782.88396|  0:00:00s\n",
            "epoch 10 | loss: 104.98503| train_rmsle: 2.75828 | train_mae: 63.44285| train_rmse: 75.31818| train_mse: 5672.82821| valid_rmsle: 2.72113 | valid_mae: 63.37732| valid_rmse: 75.21635| valid_mse: 5657.49872|  0:00:00s\n",
            "epoch 11 | loss: 97.38955| train_rmsle: 3.08616 | train_mae: 71.41024| train_rmse: 83.40182| train_mse: 6955.86347| valid_rmsle: 3.27222 | valid_mae: 75.79791| valid_rmse: 86.01854| valid_mse: 7399.18998|  0:00:00s\n",
            "epoch 12 | loss: 93.77793| train_rmsle: 1.80476 | train_mae: 43.99001| train_rmse: 62.81346| train_mse: 3945.53101| valid_rmsle: 1.78389 | valid_mae: 43.40389| valid_rmse: 61.99912| valid_mse: 3843.89042|  0:00:00s\n",
            "epoch 13 | loss: 82.67236| train_rmsle: 1.76581 | train_mae: 42.96816| train_rmse: 61.95056| train_mse: 3837.87247| valid_rmsle: 2.02741 | valid_mae: 48.07355| valid_rmse: 61.08195| valid_mse: 3731.00408|  0:00:00s\n",
            "epoch 14 | loss: 73.99331| train_rmsle: 1.76319 | train_mae: 42.56234| train_rmse: 61.32556| train_mse: 3760.82464| valid_rmsle: 1.91273 | valid_mae: 46.27356| valid_rmse: 65.87824| valid_mse: 4339.94201|  0:00:00s\n",
            "epoch 15 | loss: 69.00844| train_rmsle: 1.9185  | train_mae: 44.79297| train_rmse: 58.90211| train_mse: 3469.4586| valid_rmsle: 1.73063 | valid_mae: 39.72374| valid_rmse: 50.83169| valid_mse: 2583.8612|  0:00:00s\n",
            "epoch 16 | loss: 59.49183| train_rmsle: 2.39687 | train_mae: 55.41206| train_rmse: 69.12461| train_mse: 4778.21162| valid_rmsle: 2.18954 | valid_mae: 50.00623| valid_rmse: 60.78615| valid_mse: 3694.95635|  0:00:00s\n",
            "epoch 17 | loss: 51.50774| train_rmsle: 2.51164 | train_mae: 58.38468| train_rmse: 73.56806| train_mse: 5412.25889| valid_rmsle: 1.67136 | valid_mae: 37.82162| valid_rmse: 45.34534| valid_mse: 2056.19984|  0:00:00s\n",
            "epoch 18 | loss: 44.36754| train_rmsle: 2.46413 | train_mae: 57.73577| train_rmse: 74.911  | train_mse: 5611.65738| valid_rmsle: 2.07977 | valid_mae: 48.42081| valid_rmse: 64.58034| valid_mse: 4170.62043|  0:00:00s\n",
            "epoch 19 | loss: 36.39276| train_rmsle: 2.51977 | train_mae: 59.4758 | train_rmse: 78.61051| train_mse: 6179.61288| valid_rmsle: 2.20451 | valid_mae: 52.95211| valid_rmse: 75.51145| valid_mse: 5701.97922|  0:00:00s\n",
            "epoch 20 | loss: 33.56742| train_rmsle: 2.57341 | train_mae: 61.50579| train_rmse: 82.4748 | train_mse: 6802.09331| valid_rmsle: 2.16025 | valid_mae: 51.88934| valid_rmse: 75.02711| valid_mse: 5629.06751|  0:00:00s\n",
            "epoch 21 | loss: 25.74038| train_rmsle: 2.54387 | train_mae: 61.37439| train_rmse: 83.81067| train_mse: 7024.22781| valid_rmsle: 2.89319 | valid_mae: 72.64804| valid_rmse: 101.97202| valid_mse: 10398.29348|  0:00:01s\n",
            "epoch 22 | loss: 20.59832| train_rmsle: 2.7071  | train_mae: 65.29219| train_rmse: 87.57019| train_mse: 7668.53743| valid_rmsle: 3.82073 | valid_mae: 95.68622| valid_rmse: 122.03038| valid_mse: 14891.41381|  0:00:01s\n",
            "epoch 23 | loss: 17.27161| train_rmsle: 2.93782 | train_mae: 70.59952| train_rmse: 91.04119| train_mse: 8288.49748| valid_rmsle: 4.06839 | valid_mae: 102.7243| valid_rmse: 127.71095| valid_mse: 16310.08775|  0:00:01s\n",
            "epoch 24 | loss: 12.44409| train_rmsle: 2.90675 | train_mae: 68.51732| train_rmse: 85.48437| train_mse: 7307.578| valid_rmsle: 4.44574 | valid_mae: 114.18596| valid_rmse: 136.40531| valid_mse: 18606.40781|  0:00:01s\n",
            "epoch 25 | loss: 11.21139| train_rmsle: 2.80964 | train_mae: 66.67173| train_rmse: 84.66965| train_mse: 7168.94901| valid_rmsle: 4.24501 | valid_mae: 107.1002| valid_rmse: 127.22755| valid_mse: 16186.84827|  0:00:01s\n",
            "epoch 26 | loss: 8.78251 | train_rmsle: 3.07481 | train_mae: 74.0022 | train_rmse: 93.75107| train_mse: 8789.26342| valid_rmsle: 4.01778 | valid_mae: 100.49536| valid_rmse: 120.50036| valid_mse: 14520.337|  0:00:01s\n",
            "epoch 27 | loss: 7.95283 | train_rmsle: 3.12428 | train_mae: 75.37339| train_rmse: 95.11501| train_mse: 9046.86604| valid_rmsle: 4.65545 | valid_mae: 119.97897| valid_rmse: 143.54127| valid_mse: 20604.09721|  0:00:01s\n",
            "epoch 28 | loss: 8.1789  | train_rmsle: 3.11296 | train_mae: 73.87702| train_rmse: 90.13042| train_mse: 8123.49262| valid_rmsle: 4.65626 | valid_mae: 114.79329| valid_rmse: 126.28259| valid_mse: 15947.2926|  0:00:01s\n",
            "epoch 29 | loss: 7.58786 | train_rmsle: 2.69826 | train_mae: 63.93532| train_rmse: 80.25459| train_mse: 6440.79914| valid_rmsle: 3.14942 | valid_mae: 75.88585| valid_rmse: 92.59694| valid_mse: 8574.19379|  0:00:01s\n",
            "epoch 30 | loss: 7.00728 | train_rmsle: 2.70267 | train_mae: 63.72026| train_rmse: 79.0041 | train_mse: 6241.64738| valid_rmsle: 2.70581 | valid_mae: 64.31106| valid_rmse: 78.95889| valid_mse: 6234.50578|  0:00:01s\n",
            "epoch 31 | loss: 7.58277 | train_rmsle: 2.34047 | train_mae: 53.98699| train_rmse: 65.11041| train_mse: 4239.36527| valid_rmsle: 2.4339  | valid_mae: 55.61706| valid_rmse: 62.61013| valid_mse: 3920.02897|  0:00:01s\n",
            "epoch 32 | loss: 6.72537 | train_rmsle: 2.06467 | train_mae: 47.49289| train_rmse: 56.97671| train_mse: 3246.34565| valid_rmsle: 1.94504 | valid_mae: 44.73272| valid_rmse: 51.70973| valid_mse: 2673.8959|  0:00:01s\n",
            "epoch 33 | loss: 5.86759 | train_rmsle: 2.04133 | train_mae: 46.89623| train_rmse: 56.31392| train_mse: 3171.25777| valid_rmsle: 1.92247 | valid_mae: 43.91334| valid_rmse: 50.4556 | valid_mse: 2545.76771|  0:00:01s\n",
            "epoch 34 | loss: 4.93756 | train_rmsle: 1.94989 | train_mae: 44.64574| train_rmse: 54.05158| train_mse: 2921.57304| valid_rmsle: 1.8394  | valid_mae: 42.09206| valid_rmse: 48.04955| valid_mse: 2308.75964|  0:00:01s\n",
            "epoch 35 | loss: 4.84735 | train_rmsle: 1.72781 | train_mae: 40.09134| train_rmse: 50.21172| train_mse: 2521.21704| valid_rmsle: 1.64497 | valid_mae: 38.19377| valid_rmse: 45.15322| valid_mse: 2038.81358|  0:00:01s\n",
            "epoch 36 | loss: 3.76227 | train_rmsle: 1.80273 | train_mae: 41.34573| train_rmse: 50.44386| train_mse: 2544.58281| valid_rmsle: 2.52843 | valid_mae: 56.15603| valid_rmse: 59.98797| valid_mse: 3598.55661|  0:00:01s\n",
            "epoch 37 | loss: 2.41403 | train_rmsle: 1.54058 | train_mae: 35.42248| train_rmse: 42.64069| train_mse: 1818.22873| valid_rmsle: 2.13387 | valid_mae: 47.54193| valid_rmse: 51.48145| valid_mse: 2650.33975|  0:00:01s\n",
            "epoch 38 | loss: 3.22653 | train_rmsle: 1.35107 | train_mae: 31.34221| train_rmse: 37.53272| train_mse: 1408.70485| valid_rmsle: 1.38928 | valid_mae: 32.25154| valid_rmse: 36.10026| valid_mse: 1303.22888|  0:00:01s\n",
            "epoch 39 | loss: 2.3786  | train_rmsle: 1.23322 | train_mae: 28.8401 | train_rmse: 34.97419| train_mse: 1223.19389| valid_rmsle: 1.1378  | valid_mae: 27.47887| valid_rmse: 32.18289| valid_mse: 1035.73871|  0:00:01s\n",
            "epoch 40 | loss: 2.14089 | train_rmsle: 1.16004 | train_mae: 27.29359| train_rmse: 32.68337| train_mse: 1068.20239| valid_rmsle: 1.03808 | valid_mae: 25.14279| valid_rmse: 30.6401 | valid_mse: 938.81594|  0:00:01s\n",
            "epoch 41 | loss: 2.51644 | train_rmsle: 1.16356 | train_mae: 27.16023| train_rmse: 32.67798| train_mse: 1067.85017| valid_rmsle: 1.13311 | valid_mae: 27.25337| valid_rmse: 31.8954 | valid_mse: 1017.31642|  0:00:01s\n",
            "epoch 42 | loss: 1.98879 | train_rmsle: 1.09288 | train_mae: 25.73156| train_rmse: 31.80959| train_mse: 1011.85025| valid_rmsle: 0.87275 | valid_mae: 21.69145| valid_rmse: 26.66448| valid_mse: 710.9946|  0:00:01s\n",
            "epoch 43 | loss: 1.79182 | train_rmsle: 1.00414 | train_mae: 23.88498| train_rmse: 30.31527| train_mse: 919.01554| valid_rmsle: 0.95497 | valid_mae: 23.19223| valid_rmse: 29.1224 | valid_mse: 848.11392|  0:00:02s\n",
            "epoch 44 | loss: 1.88592 | train_rmsle: 0.82898 | train_mae: 20.40896| train_rmse: 26.94857| train_mse: 726.22556| valid_rmsle: 0.79404 | valid_mae: 20.34563| valid_rmse: 25.90051| valid_mse: 670.8362|  0:00:02s\n",
            "epoch 45 | loss: 1.71051 | train_rmsle: 0.76371 | train_mae: 18.92774| train_rmse: 25.65021| train_mse: 657.93324| valid_rmsle: 0.73998 | valid_mae: 19.1415 | valid_rmse: 24.37952| valid_mse: 594.36112|  0:00:02s\n",
            "epoch 46 | loss: 1.39062 | train_rmsle: 0.70972 | train_mae: 17.52452| train_rmse: 24.37997| train_mse: 594.38273| valid_rmsle: 0.67644 | valid_mae: 17.67424| valid_rmse: 22.50762| valid_mse: 506.59282|  0:00:02s\n",
            "epoch 47 | loss: 1.4915  | train_rmsle: 0.64126 | train_mae: 15.92843| train_rmse: 22.62532| train_mse: 511.90508| valid_rmsle: 0.57831 | valid_mae: 15.49105| valid_rmse: 19.77881| valid_mse: 391.20115|  0:00:02s\n",
            "epoch 48 | loss: 1.43124 | train_rmsle: 0.61252 | train_mae: 15.10867| train_rmse: 21.69691| train_mse: 470.75606| valid_rmsle: 0.5103  | valid_mae: 13.92304| valid_rmse: 18.10528| valid_mse: 327.80102|  0:00:02s\n",
            "epoch 49 | loss: 1.20244 | train_rmsle: 0.59245 | train_mae: 14.69134| train_rmse: 21.10261| train_mse: 445.31999| valid_rmsle: 0.42426 | valid_mae: 11.9873 | valid_rmse: 16.23962| valid_mse: 263.7251|  0:00:02s\n",
            "epoch 50 | loss: 1.11187 | train_rmsle: 0.52182 | train_mae: 13.12725| train_rmse: 19.47247| train_mse: 379.17722| valid_rmsle: 0.29282 | valid_mae: 9.10008 | valid_rmse: 12.3264 | valid_mse: 151.94017|  0:00:02s\n",
            "epoch 51 | loss: 1.06968 | train_rmsle: 0.51869 | train_mae: 13.22025| train_rmse: 19.38341| train_mse: 375.71653| valid_rmsle: 0.43431 | valid_mae: 12.16802| valid_rmse: 16.42548| valid_mse: 269.79653|  0:00:02s\n",
            "epoch 52 | loss: 0.9545  | train_rmsle: 0.71597 | train_mae: 17.23317| train_rmse: 24.00679| train_mse: 576.3259| valid_rmsle: 0.58417 | valid_mae: 14.96046| valid_rmse: 21.29686| valid_mse: 453.55612|  0:00:02s\n",
            "epoch 53 | loss: 1.07685 | train_rmsle: 0.685   | train_mae: 16.6806 | train_rmse: 22.67089| train_mse: 513.96917| valid_rmsle: 0.51474 | valid_mae: 13.18877| valid_rmse: 19.65553| valid_mse: 386.33984|  0:00:02s\n",
            "epoch 54 | loss: 1.13546 | train_rmsle: 0.62226 | train_mae: 15.6557 | train_rmse: 20.83467| train_mse: 434.08344| valid_rmsle: 0.53889 | valid_mae: 13.95494| valid_rmse: 18.91116| valid_mse: 357.63195|  0:00:02s\n",
            "epoch 55 | loss: 1.10603 | train_rmsle: 0.46948 | train_mae: 12.71385| train_rmse: 15.70592| train_mse: 246.67589| valid_rmsle: 0.4033  | valid_mae: 11.38054| valid_rmse: 14.49345| valid_mse: 210.06014|  0:00:02s\n",
            "epoch 56 | loss: 1.02861 | train_rmsle: 0.34067 | train_mae: 10.04225| train_rmse: 12.42842| train_mse: 154.46561| valid_rmsle: 0.28145 | valid_mae: 8.58827 | valid_rmse: 10.88689| valid_mse: 118.52444|  0:00:02s\n",
            "epoch 57 | loss: 1.18004 | train_rmsle: 0.33323 | train_mae: 9.93045 | train_rmse: 12.34393| train_mse: 152.3726| valid_rmsle: 0.27736 | valid_mae: 8.42215 | valid_rmse: 11.06899| valid_mse: 122.5225|  0:00:02s\n",
            "epoch 58 | loss: 1.21449 | train_rmsle: 0.25699 | train_mae: 8.15114 | train_rmse: 10.41222| train_mse: 108.41422| valid_rmsle: 0.21826 | valid_mae: 7.06542 | valid_rmse: 9.4032  | valid_mse: 88.42022|  0:00:02s\n",
            "epoch 59 | loss: 1.29153 | train_rmsle: 0.2107  | train_mae: 7.16546 | train_rmse: 9.3795  | train_mse: 87.97497| valid_rmsle: 0.16237 | valid_mae: 6.04693 | valid_rmse: 7.89473 | valid_mse: 62.32678|  0:00:02s\n",
            "epoch 60 | loss: 1.42715 | train_rmsle: 0.18643 | train_mae: 6.67877 | train_rmse: 8.55791 | train_mse: 73.23779| valid_rmsle: 0.12312 | valid_mae: 5.15804 | valid_rmse: 6.1373  | valid_mse: 37.66643|  0:00:02s\n",
            "epoch 61 | loss: 1.17035 | train_rmsle: 0.19421 | train_mae: 6.794   | train_rmse: 8.80264 | train_mse: 77.48652| valid_rmsle: 0.09177 | valid_mae: 4.06405 | valid_rmse: 5.23779 | valid_mse: 27.43439|  0:00:02s\n",
            "epoch 62 | loss: 1.20845 | train_rmsle: 0.20296 | train_mae: 6.91717 | train_rmse: 9.35456 | train_mse: 87.50776| valid_rmsle: 0.15867 | valid_mae: 5.76793 | valid_rmse: 8.14361 | valid_mse: 66.31836|  0:00:02s\n",
            "epoch 63 | loss: 1.36768 | train_rmsle: 0.21486 | train_mae: 7.04531 | train_rmse: 9.70995 | train_mse: 94.28314| valid_rmsle: 0.23934 | valid_mae: 7.2692  | valid_rmse: 10.36762| valid_mse: 107.48747|  0:00:02s\n",
            "epoch 64 | loss: 1.23391 | train_rmsle: 0.21204 | train_mae: 7.12545 | train_rmse: 9.41537 | train_mse: 88.64916| valid_rmsle: 0.25776 | valid_mae: 8.15114 | valid_rmse: 10.50679| valid_mse: 110.39255|  0:00:03s\n",
            "epoch 65 | loss: 1.77131 | train_rmsle: 0.23225 | train_mae: 7.60028 | train_rmse: 10.47303| train_mse: 109.6843| valid_rmsle: 0.43103 | valid_mae: 10.94318| valid_rmse: 17.32807| valid_mse: 300.26195|  0:00:03s\n",
            "epoch 66 | loss: 1.2372  | train_rmsle: 0.26928 | train_mae: 8.30941 | train_rmse: 11.80834| train_mse: 139.43691| valid_rmsle: 0.28123 | valid_mae: 8.29312 | valid_rmse: 11.24405| valid_mse: 126.42864|  0:00:03s\n",
            "epoch 67 | loss: 1.10428 | train_rmsle: 0.41104 | train_mae: 11.42994| train_rmse: 14.84164| train_mse: 220.27414| valid_rmsle: 0.30817 | valid_mae: 8.86469 | valid_rmse: 12.34549| valid_mse: 152.41124|  0:00:03s\n",
            "epoch 68 | loss: 1.16094 | train_rmsle: 0.54577 | train_mae: 14.15312| train_rmse: 18.11384| train_mse: 328.1112| valid_rmsle: 0.37014 | valid_mae: 10.28497| valid_rmse: 13.9681 | valid_mse: 195.10782|  0:00:03s\n",
            "epoch 69 | loss: 1.23065 | train_rmsle: 0.59285 | train_mae: 15.24814| train_rmse: 19.15394| train_mse: 366.87351| valid_rmsle: 0.4623  | valid_mae: 11.92922| valid_rmse: 16.11785| valid_mse: 259.78496|  0:00:03s\n",
            "epoch 70 | loss: 1.25015 | train_rmsle: 0.62837 | train_mae: 15.9657 | train_rmse: 19.95871| train_mse: 398.34991| valid_rmsle: 0.45417 | valid_mae: 12.38486| valid_rmse: 16.645  | valid_mse: 277.05618|  0:00:03s\n",
            "epoch 71 | loss: 1.2172  | train_rmsle: 0.62806 | train_mae: 15.89673| train_rmse: 20.31379| train_mse: 412.64991| valid_rmsle: 0.55871 | valid_mae: 14.49704| valid_rmse: 18.65085| valid_mse: 347.85423|  0:00:03s\n",
            "epoch 72 | loss: 0.96932 | train_rmsle: 0.63317 | train_mae: 15.85482| train_rmse: 20.41611| train_mse: 416.81772| valid_rmsle: 0.51804 | valid_mae: 13.49602| valid_rmse: 18.03705| valid_mse: 325.33517|  0:00:03s\n",
            "epoch 73 | loss: 1.06623 | train_rmsle: 0.56154 | train_mae: 14.39908| train_rmse: 18.58643| train_mse: 345.45557| valid_rmsle: 0.46942 | valid_mae: 12.53035| valid_rmse: 16.77014| valid_mse: 281.23763|  0:00:03s\n",
            "epoch 74 | loss: 0.97061 | train_rmsle: 0.45624 | train_mae: 12.27899| train_rmse: 16.11435| train_mse: 259.67224| valid_rmsle: 0.33233 | valid_mae: 9.61588 | valid_rmse: 13.86117| valid_mse: 192.13196|  0:00:03s\n",
            "epoch 75 | loss: 0.90269 | train_rmsle: 0.38647 | train_mae: 10.73273| train_rmse: 14.53598| train_mse: 211.29458| valid_rmsle: 0.29025 | valid_mae: 8.65718 | valid_rmse: 12.42897| valid_mse: 154.47933|  0:00:03s\n",
            "epoch 76 | loss: 0.97969 | train_rmsle: 0.32908 | train_mae: 9.45461 | train_rmse: 12.9624 | train_mse: 168.02373| valid_rmsle: 0.28391 | valid_mae: 8.57649 | valid_rmse: 11.89407| valid_mse: 141.4688|  0:00:03s\n",
            "epoch 77 | loss: 0.7657  | train_rmsle: 0.30387 | train_mae: 8.85706 | train_rmse: 12.26484| train_mse: 150.42627| valid_rmsle: 0.18955 | valid_mae: 6.3554  | valid_rmse: 9.39285 | valid_mse: 88.22564|  0:00:03s\n",
            "epoch 78 | loss: 0.86525 | train_rmsle: 0.26782 | train_mae: 7.98966 | train_rmse: 11.37422| train_mse: 129.37294| valid_rmsle: 0.20873 | valid_mae: 6.50975 | valid_rmse: 10.22341| valid_mse: 104.51819|  0:00:03s\n",
            "epoch 79 | loss: 0.92939 | train_rmsle: 0.22687 | train_mae: 7.08043 | train_rmse: 10.32677| train_mse: 106.64217| valid_rmsle: 0.16187 | valid_mae: 5.30631 | valid_rmse: 8.73688 | valid_mse: 76.33312|  0:00:03s\n",
            "epoch 80 | loss: 0.90415 | train_rmsle: 0.22795 | train_mae: 7.1845  | train_rmse: 10.20553| train_mse: 104.15287| valid_rmsle: 0.1952  | valid_mae: 6.50781 | valid_rmse: 9.24287 | valid_mse: 85.43059|  0:00:03s\n",
            "epoch 81 | loss: 0.75386 | train_rmsle: 0.21227 | train_mae: 6.85591 | train_rmse: 9.71991 | train_mse: 94.47671| valid_rmsle: 0.1699  | valid_mae: 5.91221 | valid_rmse: 8.32878 | valid_mse: 69.36866|  0:00:03s\n",
            "epoch 82 | loss: 0.91587 | train_rmsle: 0.19673 | train_mae: 6.44461 | train_rmse: 9.3029  | train_mse: 86.54394| valid_rmsle: 0.13667 | valid_mae: 4.58007 | valid_rmse: 7.44957 | valid_mse: 55.49613|  0:00:03s\n",
            "epoch 83 | loss: 0.89341 | train_rmsle: 0.16551 | train_mae: 5.67988 | train_rmse: 8.24607 | train_mse: 67.99769| valid_rmsle: 0.20947 | valid_mae: 6.65451 | valid_rmse: 9.69367 | valid_mse: 93.96729|  0:00:03s\n",
            "epoch 84 | loss: 1.08388 | train_rmsle: 0.16307 | train_mae: 5.75825 | train_rmse: 7.98234 | train_mse: 63.71774| valid_rmsle: 0.2315  | valid_mae: 7.39416 | valid_rmse: 9.53043 | valid_mse: 90.82904|  0:00:03s\n",
            "epoch 85 | loss: 1.22841 | train_rmsle: 0.21302 | train_mae: 6.97172 | train_rmse: 9.30872 | train_mse: 86.65222| valid_rmsle: 0.36888 | valid_mae: 11.09237| valid_rmse: 12.6382 | valid_mse: 159.7242|  0:00:03s\n",
            "epoch 86 | loss: 1.06465 | train_rmsle: 0.22703 | train_mae: 7.21675 | train_rmse: 9.64454 | train_mse: 93.01716| valid_rmsle: 0.39922 | valid_mae: 11.43906| valid_rmse: 13.23716| valid_mse: 175.22239|  0:00:04s\n",
            "epoch 87 | loss: 1.264   | train_rmsle: 0.23244 | train_mae: 7.36583 | train_rmse: 9.75204 | train_mse: 95.10238| valid_rmsle: 0.38263 | valid_mae: 10.99775| valid_rmse: 12.96731| valid_mse: 168.15109|  0:00:04s\n",
            "epoch 88 | loss: 1.20227 | train_rmsle: 0.23884 | train_mae: 7.52962 | train_rmse: 9.82724 | train_mse: 96.57468| valid_rmsle: 0.30342 | valid_mae: 9.13046 | valid_rmse: 11.47114| valid_mse: 131.58704|  0:00:04s\n",
            "epoch 89 | loss: 1.2212  | train_rmsle: 0.23153 | train_mae: 7.40899 | train_rmse: 9.55613 | train_mse: 91.31967| valid_rmsle: 0.21318 | valid_mae: 7.16596 | valid_rmse: 9.59612 | valid_mse: 92.08561|  0:00:04s\n",
            "epoch 90 | loss: 1.15641 | train_rmsle: 0.23809 | train_mae: 7.52945 | train_rmse: 9.69489 | train_mse: 93.99097| valid_rmsle: 0.22769 | valid_mae: 7.70501 | valid_rmse: 9.90292 | valid_mse: 98.06783|  0:00:04s\n",
            "epoch 91 | loss: 1.00093 | train_rmsle: 0.2518  | train_mae: 7.87097 | train_rmse: 10.05965| train_mse: 101.19662| valid_rmsle: 0.21528 | valid_mae: 7.21878 | valid_rmse: 9.50057 | valid_mse: 90.26087|  0:00:04s\n",
            "epoch 92 | loss: 0.98013 | train_rmsle: 0.23166 | train_mae: 7.42649 | train_rmse: 9.49377 | train_mse: 90.13171| valid_rmsle: 0.19435 | valid_mae: 6.56058 | valid_rmse: 9.00087 | valid_mse: 81.01572|  0:00:04s\n",
            "epoch 93 | loss: 0.95215 | train_rmsle: 0.22896 | train_mae: 7.39385 | train_rmse: 9.34304 | train_mse: 87.29245| valid_rmsle: 0.22667 | valid_mae: 7.68113 | valid_rmse: 9.44004 | valid_mse: 89.11426|  0:00:04s\n",
            "epoch 94 | loss: 1.05168 | train_rmsle: 0.22301 | train_mae: 7.37258 | train_rmse: 9.12406 | train_mse: 83.24855| valid_rmsle: 0.22434 | valid_mae: 7.53891 | valid_rmse: 9.33269 | valid_mse: 87.09903|  0:00:04s\n",
            "epoch 95 | loss: 1.02168 | train_rmsle: 0.19918 | train_mae: 6.72675 | train_rmse: 8.52895 | train_mse: 72.74305| valid_rmsle: 0.18524 | valid_mae: 6.57195 | valid_rmse: 8.54098 | valid_mse: 72.94839|  0:00:04s\n",
            "epoch 96 | loss: 0.79953 | train_rmsle: 0.18634 | train_mae: 6.40594 | train_rmse: 8.18329 | train_mse: 66.96619| valid_rmsle: 0.16112 | valid_mae: 5.95367 | valid_rmse: 7.58593 | valid_mse: 57.54634|  0:00:04s\n",
            "epoch 97 | loss: 0.98093 | train_rmsle: 0.16004 | train_mae: 5.66538 | train_rmse: 7.49598 | train_mse: 56.18972| valid_rmsle: 0.11373 | valid_mae: 4.62978 | valid_rmse: 5.99789 | valid_mse: 35.97464|  0:00:04s\n",
            "epoch 98 | loss: 0.97517 | train_rmsle: 0.1273  | train_mae: 4.84137 | train_rmse: 6.55498 | train_mse: 42.96783| valid_rmsle: 0.06913 | valid_mae: 3.42788 | valid_rmse: 4.3587  | valid_mse: 18.99831|  0:00:04s\n",
            "epoch 99 | loss: 1.07384 | train_rmsle: 0.0924  | train_mae: 3.82731 | train_rmse: 5.45957 | train_mse: 29.80686| valid_rmsle: 0.04909 | valid_mae: 2.60396 | valid_rmse: 3.49919 | valid_mse: 12.24436|  0:00:04s\n",
            "epoch 100| loss: 1.01051 | train_rmsle: 0.07652 | train_mae: 3.39621 | train_rmse: 4.8146  | train_mse: 23.18041| valid_rmsle: 0.04093 | valid_mae: 2.46828 | valid_rmse: 3.03881 | valid_mse: 9.23439 |  0:00:04s\n",
            "epoch 101| loss: 1.03542 | train_rmsle: 0.07741 | train_mae: 3.47035 | train_rmse: 4.78846 | train_mse: 22.92936| valid_rmsle: 0.04519 | valid_mae: 2.64163 | valid_rmse: 3.34473 | valid_mse: 11.18725|  0:00:04s\n",
            "epoch 102| loss: 0.97011 | train_rmsle: 0.07947 | train_mae: 3.57268 | train_rmse: 4.74882 | train_mse: 22.55126| valid_rmsle: 0.07896 | valid_mae: 3.42    | valid_rmse: 4.84154 | valid_mse: 23.44054|  0:00:04s\n",
            "epoch 103| loss: 1.05711 | train_rmsle: 0.0792  | train_mae: 3.53489 | train_rmse: 4.77056 | train_mse: 22.75828| valid_rmsle: 0.07976 | valid_mae: 3.45926 | valid_rmse: 4.83699 | valid_mse: 23.39645|  0:00:04s\n",
            "epoch 104| loss: 0.86863 | train_rmsle: 0.06397 | train_mae: 3.0987  | train_rmse: 4.20082 | train_mse: 17.64691| valid_rmsle: 0.04247 | valid_mae: 2.63854 | valid_rmse: 3.06634 | valid_mse: 9.40247 |  0:00:04s\n",
            "epoch 105| loss: 0.81448 | train_rmsle: 0.05395 | train_mae: 2.69153 | train_rmse: 3.78273 | train_mse: 14.30907| valid_rmsle: 0.03873 | valid_mae: 2.37897 | valid_rmse: 2.93978 | valid_mse: 8.64233 |  0:00:04s\n",
            "epoch 106| loss: 0.78382 | train_rmsle: 0.04852 | train_mae: 2.58098 | train_rmse: 3.55311 | train_mse: 12.62461| valid_rmsle: 0.03999 | valid_mae: 2.39727 | valid_rmse: 2.95048 | valid_mse: 8.70531 |  0:00:04s\n",
            "epoch 107| loss: 0.86663 | train_rmsle: 0.04486 | train_mae: 2.47268 | train_rmse: 3.38751 | train_mse: 11.47519| valid_rmsle: 0.03939 | valid_mae: 2.42891 | valid_rmse: 2.92062 | valid_mse: 8.53001 |  0:00:05s\n",
            "epoch 108| loss: 1.02702 | train_rmsle: 0.0413  | train_mae: 2.33182 | train_rmse: 3.2455  | train_mse: 10.53328| valid_rmsle: 0.03331 | valid_mae: 2.31594 | valid_rmse: 2.68668 | valid_mse: 7.21827 |  0:00:05s\n",
            "epoch 109| loss: 1.00124 | train_rmsle: 0.04177 | train_mae: 2.34675 | train_rmse: 3.26026 | train_mse: 10.62928| valid_rmsle: 0.02717 | valid_mae: 2.03189 | valid_rmse: 2.41421 | valid_mse: 5.82841 |  0:00:05s\n",
            "epoch 110| loss: 0.78656 | train_rmsle: 0.0438  | train_mae: 2.45499 | train_rmse: 3.29726 | train_mse: 10.87193| valid_rmsle: 0.0251  | valid_mae: 1.89381 | valid_rmse: 2.39703 | valid_mse: 5.74574 |  0:00:05s\n",
            "epoch 111| loss: 0.87743 | train_rmsle: 0.04788 | train_mae: 2.54373 | train_rmse: 3.32867 | train_mse: 11.08002| valid_rmsle: 0.02594 | valid_mae: 1.89432 | valid_rmse: 2.46053 | valid_mse: 6.05422 |  0:00:05s\n",
            "epoch 112| loss: 0.80556 | train_rmsle: 0.06103 | train_mae: 2.88865 | train_rmse: 3.60783 | train_mse: 13.01643| valid_rmsle: 0.03477 | valid_mae: 2.1474  | valid_rmse: 2.58982 | valid_mse: 6.70719 |  0:00:05s\n",
            "epoch 113| loss: 1.06604 | train_rmsle: 0.0707  | train_mae: 3.07949 | train_rmse: 3.76294 | train_mse: 14.15974| valid_rmsle: 0.05034 | valid_mae: 2.42551 | valid_rmse: 2.95108 | valid_mse: 8.7089  |  0:00:05s\n",
            "epoch 114| loss: 0.85937 | train_rmsle: 0.07588 | train_mae: 3.19097 | train_rmse: 3.80871 | train_mse: 14.50625| valid_rmsle: 0.05935 | valid_mae: 2.63243 | valid_rmse: 3.1051  | valid_mse: 9.64164 |  0:00:05s\n",
            "epoch 115| loss: 0.88504 | train_rmsle: 0.07674 | train_mae: 3.16642 | train_rmse: 3.76742 | train_mse: 14.19345| valid_rmsle: 0.06822 | valid_mae: 2.99837 | valid_rmse: 3.5553  | valid_mse: 12.64016|  0:00:05s\n",
            "epoch 116| loss: 1.00982 | train_rmsle: 0.07666 | train_mae: 3.16304 | train_rmse: 3.81444 | train_mse: 14.54991| valid_rmsle: 0.0558  | valid_mae: 2.69454 | valid_rmse: 3.04804 | valid_mse: 9.29053 |  0:00:05s\n",
            "epoch 117| loss: 0.897   | train_rmsle: 0.06777 | train_mae: 2.95191 | train_rmse: 3.61268 | train_mse: 13.05147| valid_rmsle: 0.05151 | valid_mae: 2.80166 | valid_rmse: 3.17828 | valid_mse: 10.10146|  0:00:05s\n",
            "epoch 118| loss: 0.84594 | train_rmsle: 0.05573 | train_mae: 2.65836 | train_rmse: 3.42305 | train_mse: 11.71724| valid_rmsle: 0.03035 | valid_mae: 2.12311 | valid_rmse: 2.69625 | valid_mse: 7.26974 |  0:00:05s\n",
            "epoch 119| loss: 0.86682 | train_rmsle: 0.04877 | train_mae: 2.46378 | train_rmse: 3.33362 | train_mse: 11.11305| valid_rmsle: 0.02808 | valid_mae: 2.03514 | valid_rmse: 2.65033 | valid_mse: 7.02423 |  0:00:05s\n",
            "epoch 120| loss: 0.89235 | train_rmsle: 0.04016 | train_mae: 2.29794 | train_rmse: 3.15833 | train_mse: 9.97507 | valid_rmsle: 0.02234 | valid_mae: 1.7538  | valid_rmse: 2.36956 | valid_mse: 5.61483 |  0:00:05s\n",
            "epoch 121| loss: 1.00769 | train_rmsle: 0.03427 | train_mae: 2.12857 | train_rmse: 2.95918 | train_mse: 8.75672 | valid_rmsle: 0.0152  | valid_mae: 1.3398  | valid_rmse: 1.89263 | valid_mse: 3.58207 |  0:00:05s\n",
            "epoch 122| loss: 0.85247 | train_rmsle: 0.02873 | train_mae: 1.9331  | train_rmse: 2.7337  | train_mse: 7.4731  | valid_rmsle: 0.01431 | valid_mae: 1.3244  | valid_rmse: 1.82464 | valid_mse: 3.32931 |  0:00:05s\n",
            "epoch 123| loss: 0.93286 | train_rmsle: 0.02931 | train_mae: 1.97951 | train_rmse: 2.76535 | train_mse: 7.64718 | valid_rmsle: 0.01436 | valid_mae: 1.41457 | valid_rmse: 1.81307 | valid_mse: 3.28723 |  0:00:05s\n",
            "epoch 124| loss: 0.8114  | train_rmsle: 0.02425 | train_mae: 1.80356 | train_rmse: 2.48814 | train_mse: 6.19086 | valid_rmsle: 0.01712 | valid_mae: 1.64313 | valid_rmse: 2.00859 | valid_mse: 4.03445 |  0:00:05s\n",
            "epoch 125| loss: 0.88629 | train_rmsle: 0.0233  | train_mae: 1.76299 | train_rmse: 2.42149 | train_mse: 5.86362 | valid_rmsle: 0.01938 | valid_mae: 1.71766 | valid_rmse: 2.1691  | valid_mse: 4.70499 |  0:00:05s\n",
            "epoch 126| loss: 0.80024 | train_rmsle: 0.02529 | train_mae: 1.83341 | train_rmse: 2.52714 | train_mse: 6.38643 | valid_rmsle: 0.01865 | valid_mae: 1.70613 | valid_rmse: 2.13544 | valid_mse: 4.56008 |  0:00:05s\n",
            "epoch 127| loss: 0.80339 | train_rmsle: 0.02634 | train_mae: 1.91893 | train_rmse: 2.59884 | train_mse: 6.75395 | valid_rmsle: 0.01934 | valid_mae: 1.77008 | valid_rmse: 2.16577 | valid_mse: 4.69057 |  0:00:06s\n",
            "epoch 128| loss: 0.72417 | train_rmsle: 0.02881 | train_mae: 2.03889 | train_rmse: 2.73211 | train_mse: 7.46444 | valid_rmsle: 0.02064 | valid_mae: 1.84947 | valid_rmse: 2.22946 | valid_mse: 4.97048 |  0:00:06s\n",
            "epoch 129| loss: 0.93358 | train_rmsle: 0.02842 | train_mae: 2.01248 | train_rmse: 2.71885 | train_mse: 7.39214 | valid_rmsle: 0.02057 | valid_mae: 1.85932 | valid_rmse: 2.22317 | valid_mse: 4.9425  |  0:00:06s\n",
            "epoch 130| loss: 0.75772 | train_rmsle: 0.02761 | train_mae: 1.97199 | train_rmse: 2.67549 | train_mse: 7.15823 | valid_rmsle: 0.02002 | valid_mae: 1.8326  | valid_rmse: 2.19041 | valid_mse: 4.7979  |  0:00:06s\n",
            "epoch 131| loss: 0.95272 | train_rmsle: 0.02706 | train_mae: 1.96887 | train_rmse: 2.62105 | train_mse: 6.86993 | valid_rmsle: 0.01979 | valid_mae: 1.83387 | valid_rmse: 2.16126 | valid_mse: 4.67105 |  0:00:06s\n",
            "epoch 132| loss: 0.70327 | train_rmsle: 0.02789 | train_mae: 2.01414 | train_rmse: 2.66805 | train_mse: 7.1185  | valid_rmsle: 0.01978 | valid_mae: 1.84611 | valid_rmse: 2.17233 | valid_mse: 4.71902 |  0:00:06s\n",
            "epoch 133| loss: 0.66406 | train_rmsle: 0.02939 | train_mae: 2.07757 | train_rmse: 2.75502 | train_mse: 7.59012 | valid_rmsle: 0.01988 | valid_mae: 1.84423 | valid_rmse: 2.19406 | valid_mse: 4.81391 |  0:00:06s\n",
            "epoch 134| loss: 0.79162 | train_rmsle: 0.03188 | train_mae: 2.18183 | train_rmse: 2.88897 | train_mse: 8.34617 | valid_rmsle: 0.02157 | valid_mae: 1.95805 | valid_rmse: 2.29576 | valid_mse: 5.27052 |  0:00:06s\n",
            "epoch 135| loss: 0.96017 | train_rmsle: 0.03227 | train_mae: 2.21046 | train_rmse: 2.91202 | train_mse: 8.47984 | valid_rmsle: 0.02516 | valid_mae: 2.08447 | valid_rmse: 2.50304 | valid_mse: 6.26521 |  0:00:06s\n",
            "epoch 136| loss: 0.72841 | train_rmsle: 0.03109 | train_mae: 2.17513 | train_rmse: 2.84884 | train_mse: 8.11587 | valid_rmsle: 0.02452 | valid_mae: 2.04042 | valid_rmse: 2.47329 | valid_mse: 6.11716 |  0:00:06s\n",
            "epoch 137| loss: 0.82785 | train_rmsle: 0.0285  | train_mae: 2.07567 | train_rmse: 2.70973 | train_mse: 7.34265 | valid_rmsle: 0.01882 | valid_mae: 1.74663 | valid_rmse: 2.15061 | valid_mse: 4.6251  |  0:00:06s\n",
            "epoch 138| loss: 0.82046 | train_rmsle: 0.0268  | train_mae: 1.98071 | train_rmse: 2.61554 | train_mse: 6.84103 | valid_rmsle: 0.01651 | valid_mae: 1.6441  | valid_rmse: 2.00342 | valid_mse: 4.01369 |  0:00:06s\n",
            "epoch 139| loss: 0.78266 | train_rmsle: 0.02735 | train_mae: 2.00624 | train_rmse: 2.6579  | train_mse: 7.06443 | valid_rmsle: 0.01559 | valid_mae: 1.58746 | valid_rmse: 1.95117 | valid_mse: 3.80706 |  0:00:06s\n",
            "epoch 140| loss: 0.68197 | train_rmsle: 0.02988 | train_mae: 2.10492 | train_rmse: 2.7983  | train_mse: 7.83049 | valid_rmsle: 0.01617 | valid_mae: 1.60147 | valid_rmse: 2.00447 | valid_mse: 4.01792 |  0:00:06s\n",
            "epoch 141| loss: 0.77972 | train_rmsle: 0.0305  | train_mae: 2.12756 | train_rmse: 2.83346 | train_mse: 8.02847 | valid_rmsle: 0.01588 | valid_mae: 1.54825 | valid_rmse: 1.99451 | valid_mse: 3.97808 |  0:00:06s\n",
            "epoch 142| loss: 0.72082 | train_rmsle: 0.03024 | train_mae: 2.12905 | train_rmse: 2.82165 | train_mse: 7.96169 | valid_rmsle: 0.01534 | valid_mae: 1.51382 | valid_rmse: 1.96451 | valid_mse: 3.8593  |  0:00:06s\n",
            "epoch 143| loss: 0.72503 | train_rmsle: 0.02874 | train_mae: 2.06214 | train_rmse: 2.75592 | train_mse: 7.59509 | valid_rmsle: 0.01433 | valid_mae: 1.48966 | valid_rmse: 1.88772 | valid_mse: 3.56349 |  0:00:06s\n",
            "epoch 144| loss: 0.70974 | train_rmsle: 0.02575 | train_mae: 1.93789 | train_rmse: 2.58835 | train_mse: 6.69953 | valid_rmsle: 0.01268 | valid_mae: 1.43201 | valid_rmse: 1.74803 | valid_mse: 3.0556  |  0:00:06s\n",
            "epoch 145| loss: 0.71478 | train_rmsle: 0.02265 | train_mae: 1.81549 | train_rmse: 2.39845 | train_mse: 5.75255 | valid_rmsle: 0.0112  | valid_mae: 1.35203 | valid_rmse: 1.62199 | valid_mse: 2.63085 |  0:00:06s\n",
            "epoch 146| loss: 0.65192 | train_rmsle: 0.02127 | train_mae: 1.7633  | train_rmse: 2.30494 | train_mse: 5.31275 | valid_rmsle: 0.00969 | valid_mae: 1.23184 | valid_rmse: 1.46587 | valid_mse: 2.14877 |  0:00:06s\n",
            "epoch 147| loss: 0.67235 | train_rmsle: 0.02325 | train_mae: 1.86489 | train_rmse: 2.40139 | train_mse: 5.7667  | valid_rmsle: 0.01381 | valid_mae: 1.5023  | valid_rmse: 1.75377 | valid_mse: 3.07572 |  0:00:06s\n",
            "epoch 148| loss: 0.6799  | train_rmsle: 0.02633 | train_mae: 2.0323  | train_rmse: 2.55685 | train_mse: 6.53746 | valid_rmsle: 0.01891 | valid_mae: 1.66863 | valid_rmse: 2.08974 | valid_mse: 4.367   |  0:00:07s\n",
            "epoch 149| loss: 0.67116 | train_rmsle: 0.02784 | train_mae: 2.10621 | train_rmse: 2.62069 | train_mse: 6.86801 | valid_rmsle: 0.02408 | valid_mae: 1.95049 | valid_rmse: 2.40127 | valid_mse: 5.76611 |  0:00:07s\n",
            "epoch 150| loss: 0.75167 | train_rmsle: 0.02669 | train_mae: 2.04078 | train_rmse: 2.54729 | train_mse: 6.4887  | valid_rmsle: 0.02484 | valid_mae: 1.96634 | valid_rmse: 2.43659 | valid_mse: 5.93699 |  0:00:07s\n",
            "epoch 151| loss: 0.65504 | train_rmsle: 0.02395 | train_mae: 1.90325 | train_rmse: 2.3895  | train_mse: 5.70973 | valid_rmsle: 0.02336 | valid_mae: 1.85488 | valid_rmse: 2.35994 | valid_mse: 5.5693  |  0:00:07s\n",
            "epoch 152| loss: 0.56732 | train_rmsle: 0.0241  | train_mae: 1.89766 | train_rmse: 2.39319 | train_mse: 5.72734 | valid_rmsle: 0.02482 | valid_mae: 1.94196 | valid_rmse: 2.45814 | valid_mse: 6.04245 |  0:00:07s\n",
            "epoch 153| loss: 0.58018 | train_rmsle: 0.02622 | train_mae: 1.98151 | train_rmse: 2.51348 | train_mse: 6.31756 | valid_rmsle: 0.02707 | valid_mae: 2.05666 | valid_rmse: 2.57735 | valid_mse: 6.64273 |  0:00:07s\n",
            "epoch 154| loss: 0.66352 | train_rmsle: 0.02756 | train_mae: 2.02815 | train_rmse: 2.58131 | train_mse: 6.66317 | valid_rmsle: 0.02962 | valid_mae: 2.16517 | valid_rmse: 2.69291 | valid_mse: 7.25178 |  0:00:07s\n",
            "epoch 155| loss: 0.79038 | train_rmsle: 0.02838 | train_mae: 2.05933 | train_rmse: 2.62179 | train_mse: 6.87378 | valid_rmsle: 0.03164 | valid_mae: 2.27207 | valid_rmse: 2.78261 | valid_mse: 7.74291 |  0:00:07s\n",
            "epoch 156| loss: 0.61249 | train_rmsle: 0.0275  | train_mae: 2.00565 | train_rmse: 2.57254 | train_mse: 6.61798 | valid_rmsle: 0.03166 | valid_mae: 2.31962 | valid_rmse: 2.76997 | valid_mse: 7.67274 |  0:00:07s\n",
            "epoch 157| loss: 0.6636  | train_rmsle: 0.02585 | train_mae: 1.92829 | train_rmse: 2.47923 | train_mse: 6.14658 | valid_rmsle: 0.03081 | valid_mae: 2.28366 | valid_rmse: 2.71529 | valid_mse: 7.37279 |  0:00:07s\n",
            "epoch 158| loss: 0.66343 | train_rmsle: 0.02773 | train_mae: 2.01617 | train_rmse: 2.57313 | train_mse: 6.62099 | valid_rmsle: 0.03342 | valid_mae: 2.38766 | valid_rmse: 2.83282 | valid_mse: 8.02489 |  0:00:07s\n",
            "epoch 159| loss: 0.75044 | train_rmsle: 0.02801 | train_mae: 2.01754 | train_rmse: 2.57101 | train_mse: 6.61009 | valid_rmsle: 0.03413 | valid_mae: 2.40766 | valid_rmse: 2.86703 | valid_mse: 8.21984 |  0:00:07s\n",
            "epoch 160| loss: 0.59596 | train_rmsle: 0.0275  | train_mae: 1.99315 | train_rmse: 2.54466 | train_mse: 6.47532 | valid_rmsle: 0.03288 | valid_mae: 2.35303 | valid_rmse: 2.80907 | valid_mse: 7.89088 |  0:00:07s\n",
            "epoch 161| loss: 0.49631 | train_rmsle: 0.0264  | train_mae: 1.93174 | train_rmse: 2.48531 | train_mse: 6.17678 | valid_rmsle: 0.03223 | valid_mae: 2.33359 | valid_rmse: 2.77548 | valid_mse: 7.70328 |  0:00:07s\n",
            "epoch 162| loss: 0.59852 | train_rmsle: 0.02561 | train_mae: 1.92587 | train_rmse: 2.43974 | train_mse: 5.95235 | valid_rmsle: 0.03149 | valid_mae: 2.30877 | valid_rmse: 2.7358  | valid_mse: 7.4846  |  0:00:07s\n",
            "epoch 163| loss: 0.88625 | train_rmsle: 0.02461 | train_mae: 1.86897 | train_rmse: 2.38703 | train_mse: 5.69791 | valid_rmsle: 0.03125 | valid_mae: 2.29722 | valid_rmse: 2.71677 | valid_mse: 7.38081 |  0:00:07s\n",
            "epoch 164| loss: 0.72909 | train_rmsle: 0.02541 | train_mae: 1.93029 | train_rmse: 2.42297 | train_mse: 5.8708  | valid_rmsle: 0.03237 | valid_mae: 2.32987 | valid_rmse: 2.77017 | valid_mse: 7.67385 |  0:00:07s\n",
            "epoch 165| loss: 0.7124  | train_rmsle: 0.02777 | train_mae: 2.03493 | train_rmse: 2.54408 | train_mse: 6.47234 | valid_rmsle: 0.03435 | valid_mae: 2.3562  | valid_rmse: 2.86943 | valid_mse: 8.23361 |  0:00:07s\n",
            "epoch 166| loss: 0.88426 | train_rmsle: 0.02988 | train_mae: 2.12985 | train_rmse: 2.64977 | train_mse: 7.02126 | valid_rmsle: 0.03727 | valid_mae: 2.43439 | valid_rmse: 3.01148 | valid_mse: 9.06902 |  0:00:07s\n",
            "epoch 167| loss: 0.97838 | train_rmsle: 0.03013 | train_mae: 2.13535 | train_rmse: 2.6648  | train_mse: 7.10116 | valid_rmsle: 0.03919 | valid_mae: 2.51329 | valid_rmse: 3.10542 | valid_mse: 9.64366 |  0:00:07s\n",
            "epoch 168| loss: 0.68789 | train_rmsle: 0.02957 | train_mae: 2.08719 | train_rmse: 2.64253 | train_mse: 6.98295 | valid_rmsle: 0.0372  | valid_mae: 2.44774 | valid_rmse: 3.00363 | valid_mse: 9.02181 |  0:00:07s\n",
            "epoch 169| loss: 0.91654 | train_rmsle: 0.02984 | train_mae: 2.09871 | train_rmse: 2.66026 | train_mse: 7.077   | valid_rmsle: 0.03405 | valid_mae: 2.30534 | valid_rmse: 2.86549 | valid_mse: 8.21106 |  0:00:07s\n",
            "epoch 170| loss: 0.5195  | train_rmsle: 0.03066 | train_mae: 2.13642 | train_rmse: 2.70135 | train_mse: 7.29727 | valid_rmsle: 0.03312 | valid_mae: 2.23873 | valid_rmse: 2.83168 | valid_mse: 8.01841 |  0:00:08s\n",
            "epoch 171| loss: 0.61493 | train_rmsle: 0.03014 | train_mae: 2.13568 | train_rmse: 2.67389 | train_mse: 7.1497  | valid_rmsle: 0.03351 | valid_mae: 2.23345 | valid_rmse: 2.84911 | valid_mse: 8.11742 |  0:00:08s\n",
            "epoch 172| loss: 0.59007 | train_rmsle: 0.02652 | train_mae: 1.96831 | train_rmse: 2.49052 | train_mse: 6.20268 | valid_rmsle: 0.03166 | valid_mae: 2.16034 | valid_rmse: 2.75529 | valid_mse: 7.59162 |  0:00:08s\n",
            "epoch 173| loss: 0.75197 | train_rmsle: 0.02237 | train_mae: 1.77398 | train_rmse: 2.27128 | train_mse: 5.15873 | valid_rmsle: 0.02838 | valid_mae: 2.03084 | valid_rmse: 2.59025 | valid_mse: 6.70939 |  0:00:08s\n",
            "epoch 174| loss: 0.58992 | train_rmsle: 0.01896 | train_mae: 1.62576 | train_rmse: 2.07687 | train_mse: 4.31341 | valid_rmsle: 0.02483 | valid_mae: 1.92917 | valid_rmse: 2.40127 | valid_mse: 5.76608 |  0:00:08s\n",
            "epoch 175| loss: 0.76088 | train_rmsle: 0.01686 | train_mae: 1.52028 | train_rmse: 1.95542 | train_mse: 3.82368 | valid_rmsle: 0.02094 | valid_mae: 1.82919 | valid_rmse: 2.2085  | valid_mse: 4.87749 |  0:00:08s\n",
            "epoch 176| loss: 0.79186 | train_rmsle: 0.01536 | train_mae: 1.41838 | train_rmse: 1.8775  | train_mse: 3.52499 | valid_rmsle: 0.02081 | valid_mae: 1.82633 | valid_rmse: 2.19565 | valid_mse: 4.82088 |  0:00:08s\n",
            "epoch 177| loss: 0.74213 | train_rmsle: 0.0166  | train_mae: 1.49583 | train_rmse: 1.9645  | train_mse: 3.85926 | valid_rmsle: 0.01898 | valid_mae: 1.71072 | valid_rmse: 2.1208  | valid_mse: 4.49778 |  0:00:08s\n",
            "epoch 178| loss: 0.87067 | train_rmsle: 0.01928 | train_mae: 1.65231 | train_rmse: 2.12332 | train_mse: 4.50849 | valid_rmsle: 0.01812 | valid_mae: 1.64927 | valid_rmse: 2.09741 | valid_mse: 4.39913 |  0:00:08s\n",
            "epoch 179| loss: 0.84065 | train_rmsle: 0.02082 | train_mae: 1.73536 | train_rmse: 2.2075  | train_mse: 4.87306 | valid_rmsle: 0.02026 | valid_mae: 1.86919 | valid_rmse: 2.20975 | valid_mse: 4.88301 |  0:00:08s\n",
            "epoch 180| loss: 0.90655 | train_rmsle: 0.01964 | train_mae: 1.68855 | train_rmse: 2.14135 | train_mse: 4.58537 | valid_rmsle: 0.01957 | valid_mae: 1.87831 | valid_rmse: 2.15748 | valid_mse: 4.65471 |  0:00:08s\n",
            "epoch 181| loss: 0.79124 | train_rmsle: 0.01731 | train_mae: 1.56254 | train_rmse: 2.00163 | train_mse: 4.00652 | valid_rmsle: 0.01726 | valid_mae: 1.7559  | valid_rmse: 2.00823 | valid_mse: 4.03298 |  0:00:08s\n",
            "epoch 182| loss: 0.70761 | train_rmsle: 0.01512 | train_mae: 1.41762 | train_rmse: 1.8648  | train_mse: 3.47749 | valid_rmsle: 0.0147  | valid_mae: 1.61689 | valid_rmse: 1.83228 | valid_mse: 3.35727 |  0:00:08s\n",
            "epoch 183| loss: 0.55363 | train_rmsle: 0.01385 | train_mae: 1.34299 | train_rmse: 1.76918 | train_mse: 3.12999 | valid_rmsle: 0.01223 | valid_mae: 1.45193 | valid_rmse: 1.64657 | valid_mse: 2.71119 |  0:00:08s\n",
            "epoch 184| loss: 0.70781 | train_rmsle: 0.01383 | train_mae: 1.35103 | train_rmse: 1.76989 | train_mse: 3.13251 | valid_rmsle: 0.01186 | valid_mae: 1.43845 | valid_rmse: 1.60921 | valid_mse: 2.58957 |  0:00:08s\n",
            "epoch 185| loss: 0.62552 | train_rmsle: 0.01505 | train_mae: 1.43842 | train_rmse: 1.85324 | train_mse: 3.43449 | valid_rmsle: 0.01274 | valid_mae: 1.47651 | valid_rmse: 1.66934 | valid_mse: 2.78669 |  0:00:08s\n",
            "epoch 186| loss: 0.65087 | train_rmsle: 0.01628 | train_mae: 1.50877 | train_rmse: 1.93717 | train_mse: 3.75264 | valid_rmsle: 0.01423 | valid_mae: 1.56027 | valid_rmse: 1.7721  | valid_mse: 3.14033 |  0:00:08s\n",
            "epoch 187| loss: 0.80796 | train_rmsle: 0.01668 | train_mae: 1.53104 | train_rmse: 1.96125 | train_mse: 3.84651 | valid_rmsle: 0.01439 | valid_mae: 1.56716 | valid_rmse: 1.7809  | valid_mse: 3.17159 |  0:00:08s\n",
            "epoch 188| loss: 0.81668 | train_rmsle: 0.01568 | train_mae: 1.45479 | train_rmse: 1.89476 | train_mse: 3.59012 | valid_rmsle: 0.01336 | valid_mae: 1.50246 | valid_rmse: 1.70811 | valid_mse: 2.91764 |  0:00:08s\n",
            "epoch 189| loss: 0.73684 | train_rmsle: 0.01483 | train_mae: 1.39314 | train_rmse: 1.83786 | train_mse: 3.37773 | valid_rmsle: 0.01242 | valid_mae: 1.43774 | valid_rmse: 1.63793 | valid_mse: 2.68281 |  0:00:08s\n",
            "epoch 190| loss: 0.68654 | train_rmsle: 0.01375 | train_mae: 1.32954 | train_rmse: 1.76342 | train_mse: 3.10964 | valid_rmsle: 0.01157 | valid_mae: 1.38649 | valid_rmse: 1.57398 | valid_mse: 2.47742 |  0:00:08s\n",
            "epoch 191| loss: 0.6173  | train_rmsle: 0.01325 | train_mae: 1.32206 | train_rmse: 1.72502 | train_mse: 2.97569 | valid_rmsle: 0.0116  | valid_mae: 1.39409 | valid_rmse: 1.572   | valid_mse: 2.47119 |  0:00:08s\n",
            "epoch 192| loss: 0.67717 | train_rmsle: 0.01374 | train_mae: 1.36629 | train_rmse: 1.75644 | train_mse: 3.0851  | valid_rmsle: 0.01228 | valid_mae: 1.4456  | valid_rmse: 1.61682 | valid_mse: 2.61409 |  0:00:09s\n",
            "epoch 193| loss: 0.93295 | train_rmsle: 0.01374 | train_mae: 1.37759 | train_rmse: 1.75301 | train_mse: 3.07305 | valid_rmsle: 0.01177 | valid_mae: 1.41172 | valid_rmse: 1.57468 | valid_mse: 2.47962 |  0:00:09s\n",
            "epoch 194| loss: 0.81449 | train_rmsle: 0.01381 | train_mae: 1.37953 | train_rmse: 1.74968 | train_mse: 3.06137 | valid_rmsle: 0.0111  | valid_mae: 1.35245 | valid_rmse: 1.51945 | valid_mse: 2.30872 |  0:00:09s\n",
            "epoch 195| loss: 0.58654 | train_rmsle: 0.01276 | train_mae: 1.30851 | train_rmse: 1.66816 | train_mse: 2.78276 | valid_rmsle: 0.00977 | valid_mae: 1.24048 | valid_rmse: 1.41676 | valid_mse: 2.0072  |  0:00:09s\n",
            "epoch 196| loss: 0.70883 | train_rmsle: 0.01092 | train_mae: 1.19046 | train_rmse: 1.53554 | train_mse: 2.35789 | valid_rmsle: 0.00812 | valid_mae: 1.08236 | valid_rmse: 1.27952 | valid_mse: 1.63716 |  0:00:09s\n",
            "epoch 197| loss: 0.72557 | train_rmsle: 0.00984 | train_mae: 1.10643 | train_rmse: 1.45344 | train_mse: 2.11248 | valid_rmsle: 0.00723 | valid_mae: 0.93595 | valid_rmse: 1.20144 | valid_mse: 1.44345 |  0:00:09s\n",
            "epoch 198| loss: 0.77309 | train_rmsle: 0.00945 | train_mae: 1.09077 | train_rmse: 1.42644 | train_mse: 2.03472 | valid_rmsle: 0.00719 | valid_mae: 0.93336 | valid_rmse: 1.19671 | valid_mse: 1.43211 |  0:00:09s\n",
            "epoch 199| loss: 0.73951 | train_rmsle: 0.00935 | train_mae: 1.09903 | train_rmse: 1.42556 | train_mse: 2.03222 | valid_rmsle: 0.00703 | valid_mae: 0.96255 | valid_rmse: 1.17891 | valid_mse: 1.38984 |  0:00:09s\n",
            "epoch 200| loss: 0.61825 | train_rmsle: 0.00888 | train_mae: 1.05702 | train_rmse: 1.38997 | train_mse: 1.93203 | valid_rmsle: 0.00587 | valid_mae: 0.90014 | valid_rmse: 1.07594 | valid_mse: 1.15764 |  0:00:09s\n",
            "epoch 201| loss: 0.73036 | train_rmsle: 0.00794 | train_mae: 0.98007 | train_rmse: 1.31247 | train_mse: 1.72259 | valid_rmsle: 0.00528 | valid_mae: 0.88035 | valid_rmse: 1.02459 | valid_mse: 1.04979 |  0:00:09s\n",
            "epoch 202| loss: 0.68829 | train_rmsle: 0.00723 | train_mae: 0.90907 | train_rmse: 1.25134 | train_mse: 1.56586 | valid_rmsle: 0.00508 | valid_mae: 0.88953 | valid_rmse: 1.0135  | valid_mse: 1.02718 |  0:00:09s\n",
            "epoch 203| loss: 0.61809 | train_rmsle: 0.007   | train_mae: 0.8879  | train_rmse: 1.23075 | train_mse: 1.51476 | valid_rmsle: 0.00556 | valid_mae: 0.92549 | valid_rmse: 1.06293 | valid_mse: 1.12982 |  0:00:09s\n",
            "epoch 204| loss: 0.63302 | train_rmsle: 0.0072  | train_mae: 0.90932 | train_rmse: 1.24713 | train_mse: 1.55533 | valid_rmsle: 0.00556 | valid_mae: 0.93835 | valid_rmse: 1.05828 | valid_mse: 1.11996 |  0:00:09s\n",
            "epoch 205| loss: 0.52951 | train_rmsle: 0.00754 | train_mae: 0.94245 | train_rmse: 1.27692 | train_mse: 1.63052 | valid_rmsle: 0.00672 | valid_mae: 1.00514 | valid_rmse: 1.15726 | valid_mse: 1.33925 |  0:00:09s\n",
            "epoch 206| loss: 0.58465 | train_rmsle: 0.00815 | train_mae: 1.00661 | train_rmse: 1.32503 | train_mse: 1.75569 | valid_rmsle: 0.00834 | valid_mae: 1.04055 | valid_rmse: 1.29215 | valid_mse: 1.66966 |  0:00:09s\n",
            "epoch 207| loss: 0.70607 | train_rmsle: 0.00878 | train_mae: 1.04808 | train_rmse: 1.37044 | train_mse: 1.8781  | valid_rmsle: 0.00899 | valid_mae: 1.05035 | valid_rmse: 1.3414  | valid_mse: 1.79935 |  0:00:09s\n",
            "epoch 208| loss: 0.57007 | train_rmsle: 0.00887 | train_mae: 1.04484 | train_rmse: 1.37161 | train_mse: 1.8813  | valid_rmsle: 0.00922 | valid_mae: 1.09113 | valid_rmse: 1.35854 | valid_mse: 1.84563 |  0:00:09s\n",
            "epoch 209| loss: 0.61583 | train_rmsle: 0.00855 | train_mae: 1.01286 | train_rmse: 1.34291 | train_mse: 1.8034  | valid_rmsle: 0.00908 | valid_mae: 1.11328 | valid_rmse: 1.34772 | valid_mse: 1.81634 |  0:00:09s\n",
            "epoch 210| loss: 0.52755 | train_rmsle: 0.00813 | train_mae: 0.99045 | train_rmse: 1.30925 | train_mse: 1.71413 | valid_rmsle: 0.00859 | valid_mae: 1.08664 | valid_rmse: 1.31053 | valid_mse: 1.71748 |  0:00:09s\n",
            "epoch 211| loss: 0.55543 | train_rmsle: 0.0082  | train_mae: 0.99258 | train_rmse: 1.31633 | train_mse: 1.73273 | valid_rmsle: 0.00841 | valid_mae: 1.06969 | valid_rmse: 1.29747 | valid_mse: 1.68342 |  0:00:09s\n",
            "epoch 212| loss: 0.65161 | train_rmsle: 0.00847 | train_mae: 1.01089 | train_rmse: 1.34229 | train_mse: 1.80175 | valid_rmsle: 0.00849 | valid_mae: 1.06433 | valid_rmse: 1.30365 | valid_mse: 1.69949 |  0:00:10s\n",
            "epoch 213| loss: 0.52148 | train_rmsle: 0.0092  | train_mae: 1.07364 | train_rmse: 1.40014 | train_mse: 1.96039 | valid_rmsle: 0.00896 | valid_mae: 1.08145 | valid_rmse: 1.34329 | valid_mse: 1.80442 |  0:00:10s\n",
            "epoch 214| loss: 0.69221 | train_rmsle: 0.00978 | train_mae: 1.11614 | train_rmse: 1.44589 | train_mse: 2.09061 | valid_rmsle: 0.0096  | valid_mae: 1.14372 | valid_rmse: 1.39615 | valid_mse: 1.94924 |  0:00:10s\n",
            "epoch 215| loss: 0.58037 | train_rmsle: 0.00989 | train_mae: 1.13122 | train_rmse: 1.45562 | train_mse: 2.11882 | valid_rmsle: 0.00924 | valid_mae: 1.13011 | valid_rmse: 1.37345 | valid_mse: 1.88636 |  0:00:10s\n",
            "epoch 216| loss: 0.52151 | train_rmsle: 0.00958 | train_mae: 1.11436 | train_rmse: 1.4297  | train_mse: 2.04403 | valid_rmsle: 0.00817 | valid_mae: 1.07472 | valid_rmse: 1.29066 | valid_mse: 1.66581 |  0:00:10s\n",
            "epoch 217| loss: 0.54173 | train_rmsle: 0.00928 | train_mae: 1.08327 | train_rmse: 1.40369 | train_mse: 1.97035 | valid_rmsle: 0.00777 | valid_mae: 1.04777 | valid_rmse: 1.25801 | valid_mse: 1.58258 |  0:00:10s\n",
            "epoch 218| loss: 0.67506 | train_rmsle: 0.00938 | train_mae: 1.08534 | train_rmse: 1.40763 | train_mse: 1.98142 | valid_rmsle: 0.00791 | valid_mae: 1.06388 | valid_rmse: 1.26983 | valid_mse: 1.61246 |  0:00:10s\n",
            "epoch 219| loss: 0.60254 | train_rmsle: 0.00945 | train_mae: 1.08729 | train_rmse: 1.41579 | train_mse: 2.00447 | valid_rmsle: 0.00813 | valid_mae: 1.08582 | valid_rmse: 1.29072 | valid_mse: 1.66596 |  0:00:10s\n",
            "epoch 220| loss: 0.48716 | train_rmsle: 0.0098  | train_mae: 1.12446 | train_rmse: 1.44414 | train_mse: 2.08553 | valid_rmsle: 0.00848 | valid_mae: 1.11624 | valid_rmse: 1.32162 | valid_mse: 1.74669 |  0:00:10s\n",
            "epoch 221| loss: 0.6091  | train_rmsle: 0.00941 | train_mae: 1.10525 | train_rmse: 1.41922 | train_mse: 2.01418 | valid_rmsle: 0.00841 | valid_mae: 1.1328  | valid_rmse: 1.31753 | valid_mse: 1.73588 |  0:00:10s\n",
            "epoch 222| loss: 0.4428  | train_rmsle: 0.00857 | train_mae: 1.03414 | train_rmse: 1.349   | train_mse: 1.81979 | valid_rmsle: 0.00799 | valid_mae: 1.10649 | valid_rmse: 1.28242 | valid_mse: 1.64459 |  0:00:10s\n",
            "epoch 223| loss: 0.58774 | train_rmsle: 0.00768 | train_mae: 0.95509 | train_rmse: 1.26947 | train_mse: 1.61155 | valid_rmsle: 0.00731 | valid_mae: 1.02919 | valid_rmse: 1.22355 | valid_mse: 1.49709 |  0:00:10s\n",
            "epoch 224| loss: 0.55549 | train_rmsle: 0.00738 | train_mae: 0.91707 | train_rmse: 1.22299 | train_mse: 1.49571 | valid_rmsle: 0.00649 | valid_mae: 0.91035 | valid_rmse: 1.15019 | valid_mse: 1.32294 |  0:00:10s\n",
            "epoch 225| loss: 0.5374  | train_rmsle: 0.00736 | train_mae: 0.92307 | train_rmse: 1.22117 | train_mse: 1.49125 | valid_rmsle: 0.00619 | valid_mae: 0.89095 | valid_rmse: 1.12224 | valid_mse: 1.25943 |  0:00:10s\n",
            "epoch 226| loss: 0.55328 | train_rmsle: 0.00738 | train_mae: 0.94396 | train_rmse: 1.22167 | train_mse: 1.49249 | valid_rmsle: 0.00661 | valid_mae: 0.91562 | valid_rmse: 1.16098 | valid_mse: 1.34788 |  0:00:10s\n",
            "epoch 227| loss: 0.58266 | train_rmsle: 0.00737 | train_mae: 0.955   | train_rmse: 1.22063 | train_mse: 1.48994 | valid_rmsle: 0.00709 | valid_mae: 0.97629 | valid_rmse: 1.20528 | valid_mse: 1.45271 |  0:00:10s\n",
            "epoch 228| loss: 0.63736 | train_rmsle: 0.0078  | train_mae: 0.99555 | train_rmse: 1.25465 | train_mse: 1.57414 | valid_rmsle: 0.0082  | valid_mae: 1.08999 | valid_rmse: 1.30223 | valid_mse: 1.69579 |  0:00:10s\n",
            "epoch 229| loss: 0.73561 | train_rmsle: 0.00826 | train_mae: 1.03182 | train_rmse: 1.28881 | train_mse: 1.66102 | valid_rmsle: 0.00909 | valid_mae: 1.19308 | valid_rmse: 1.37622 | valid_mse: 1.89399 |  0:00:10s\n",
            "epoch 230| loss: 0.60813 | train_rmsle: 0.00836 | train_mae: 1.03768 | train_rmse: 1.2932  | train_mse: 1.67236 | valid_rmsle: 0.00929 | valid_mae: 1.22205 | valid_rmse: 1.39345 | valid_mse: 1.94172 |  0:00:10s\n",
            "epoch 231| loss: 0.48243 | train_rmsle: 0.00822 | train_mae: 1.02593 | train_rmse: 1.27888 | train_mse: 1.63554 | valid_rmsle: 0.00911 | valid_mae: 1.21826 | valid_rmse: 1.38058 | valid_mse: 1.90601 |  0:00:10s\n",
            "epoch 232| loss: 0.50667 | train_rmsle: 0.00828 | train_mae: 1.01211 | train_rmse: 1.28223 | train_mse: 1.64411 | valid_rmsle: 0.00904 | valid_mae: 1.21675 | valid_rmse: 1.37852 | valid_mse: 1.90033 |  0:00:10s\n",
            "epoch 233| loss: 0.54305 | train_rmsle: 0.00832 | train_mae: 1.00193 | train_rmse: 1.29035 | train_mse: 1.66501 | valid_rmsle: 0.00924 | valid_mae: 1.23981 | valid_rmse: 1.39812 | valid_mse: 1.95473 |  0:00:11s\n",
            "epoch 234| loss: 0.62657 | train_rmsle: 0.00861 | train_mae: 1.00525 | train_rmse: 1.32156 | train_mse: 1.74652 | valid_rmsle: 0.00979 | valid_mae: 1.28619 | valid_rmse: 1.44653 | valid_mse: 2.09244 |  0:00:11s\n",
            "epoch 235| loss: 0.54109 | train_rmsle: 0.00877 | train_mae: 1.02771 | train_rmse: 1.34465 | train_mse: 1.80807 | valid_rmsle: 0.01117 | valid_mae: 1.40859 | valid_rmse: 1.55527 | valid_mse: 2.41888 |  0:00:11s\n",
            "epoch 236| loss: 0.4652  | train_rmsle: 0.0095  | train_mae: 1.08443 | train_rmse: 1.40784 | train_mse: 1.98202 | valid_rmsle: 0.01317 | valid_mae: 1.56614 | valid_rmse: 1.69875 | valid_mse: 2.88576 |  0:00:11s\n",
            "epoch 237| loss: 0.46027 | train_rmsle: 0.00992 | train_mae: 1.12218 | train_rmse: 1.44153 | train_mse: 2.07802 | valid_rmsle: 0.01423 | valid_mae: 1.62818 | valid_rmse: 1.76569 | valid_mse: 3.11765 |  0:00:11s\n",
            "epoch 238| loss: 0.49927 | train_rmsle: 0.00946 | train_mae: 1.10065 | train_rmse: 1.40209 | train_mse: 1.96585 | valid_rmsle: 0.01388 | valid_mae: 1.58729 | valid_rmse: 1.73705 | valid_mse: 3.01733 |  0:00:11s\n",
            "epoch 239| loss: 0.4596  | train_rmsle: 0.00873 | train_mae: 1.05598 | train_rmse: 1.34165 | train_mse: 1.80002 | valid_rmsle: 0.01256 | valid_mae: 1.47414 | valid_rmse: 1.64144 | valid_mse: 2.69432 |  0:00:11s\n",
            "epoch 240| loss: 0.53947 | train_rmsle: 0.00797 | train_mae: 1.003   | train_rmse: 1.27607 | train_mse: 1.62836 | valid_rmsle: 0.01125 | valid_mae: 1.33379 | valid_rmse: 1.54108 | valid_mse: 2.37494 |  0:00:11s\n",
            "epoch 241| loss: 0.52305 | train_rmsle: 0.00786 | train_mae: 0.99729 | train_rmse: 1.26512 | train_mse: 1.60053 | valid_rmsle: 0.01088 | valid_mae: 1.30067 | valid_rmse: 1.50786 | valid_mse: 2.27365 |  0:00:11s\n",
            "epoch 242| loss: 0.47955 | train_rmsle: 0.00795 | train_mae: 0.99166 | train_rmse: 1.27282 | train_mse: 1.62007 | valid_rmsle: 0.01113 | valid_mae: 1.31946 | valid_rmse: 1.52276 | valid_mse: 2.31878 |  0:00:11s\n",
            "epoch 243| loss: 0.55126 | train_rmsle: 0.00811 | train_mae: 1.00007 | train_rmse: 1.28752 | train_mse: 1.65772 | valid_rmsle: 0.01178 | valid_mae: 1.35216 | valid_rmse: 1.5679  | valid_mse: 2.45832 |  0:00:11s\n",
            "epoch 244| loss: 0.40844 | train_rmsle: 0.00873 | train_mae: 1.04299 | train_rmse: 1.33769 | train_mse: 1.78941 | valid_rmsle: 0.01191 | valid_mae: 1.33172 | valid_rmse: 1.58138 | valid_mse: 2.50078 |  0:00:11s\n",
            "epoch 245| loss: 0.50471 | train_rmsle: 0.0086  | train_mae: 1.04614 | train_rmse: 1.33219 | train_mse: 1.77473 | valid_rmsle: 0.01199 | valid_mae: 1.33583 | valid_rmse: 1.58776 | valid_mse: 2.521   |  0:00:11s\n",
            "epoch 246| loss: 0.49495 | train_rmsle: 0.00827 | train_mae: 1.01458 | train_rmse: 1.30273 | train_mse: 1.69709 | valid_rmsle: 0.01134 | valid_mae: 1.30914 | valid_rmse: 1.54078 | valid_mse: 2.37401 |  0:00:11s\n",
            "epoch 247| loss: 0.41049 | train_rmsle: 0.00755 | train_mae: 0.95874 | train_rmse: 1.24094 | train_mse: 1.53993 | valid_rmsle: 0.01    | valid_mae: 1.23048 | valid_rmse: 1.44069 | valid_mse: 2.07558 |  0:00:11s\n",
            "epoch 248| loss: 0.49947 | train_rmsle: 0.00703 | train_mae: 0.91692 | train_rmse: 1.19919 | train_mse: 1.43806 | valid_rmsle: 0.00958 | valid_mae: 1.20497 | valid_rmse: 1.40909 | valid_mse: 1.98553 |  0:00:11s\n",
            "epoch 249| loss: 0.46435 | train_rmsle: 0.00695 | train_mae: 0.90259 | train_rmse: 1.19159 | train_mse: 1.41988 | valid_rmsle: 0.00959 | valid_mae: 1.19264 | valid_rmse: 1.40932 | valid_mse: 1.9862  |  0:00:11s\n",
            "Stop training because you reached max_epochs = 250 with best_epoch = 202 and best_valid_mse = 1.02718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odOW1t3-LY-s",
        "outputId": "72e0dd3f-a70f-4a23-9173-123203bbaa6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabNetRegressor(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=[5, 4, 3, 6, 2, 2, 1, 10], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=55, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deprecated : best model is automatically loaded at end of fit\n",
        "# clf.load_best_model()\n",
        "\n",
        "preds = clf.predict(X_test)\n",
        "\n",
        "y_true = y_test\n",
        "\n",
        "test_score = mean_squared_error(y_pred=preds, y_true=y_true) #MSE\n",
        "\n",
        "dataset_name = \"allApple\"\n",
        "print(f\"BEST VALID SCORE FOR {dataset_name} : {clf.best_cost}\")\n",
        "print(f\"FINAL TEST SCORE FOR {dataset_name} : {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHdhaNdA921z",
        "outputId": "032da2fe-208f-40dd-f984-5e6b08dffbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST VALID SCORE FOR allApple : 1.0271841593662734\n",
            "FINAL TEST SCORE FOR allApple : 2.6039192697497575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save tabnet model\n",
        "saving_path_name = \"./tabnet_model_test_1\"\n",
        "saved_filepath = clf.save_model(saving_path_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdM7TDnP-b13",
        "outputId": "25f8a3a8-97b8-4726-e803-acc744b1dd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at ./tabnet_model_test_1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define new model with basic parameters and load state dict weights\n",
        "loaded_clf = TabNetRegressor()\n",
        "loaded_clf.load_model(saved_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmD37fut-np4",
        "outputId": "58142b30-2804-4dfd-8d3e-0006cd478270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_preds = loaded_clf.predict(X_test)\n",
        "loaded_test_mse = mean_squared_error(loaded_preds, y_test)\n",
        "\n",
        "print(f\"FINAL TEST SCORE FOR {dataset_name} : {loaded_test_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fmSX6fO-tvt",
        "outputId": "e550424a-6db8-4b78-9eca-2bf342dd604e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL TEST SCORE FOR allApple : 2.6039192697497575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert(test_score == loaded_test_mse)"
      ],
      "metadata": {
        "id": "ZKY1_Elg-x0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Global explainability : feat importance summing to 1"
      ],
      "metadata": {
        "id": "dnF8HiM9_Ffc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.feature_importances_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qGAL0fD_Dyx",
        "outputId": "7ff53150-f086-47de-89de-7718c3023a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 4.35585549e-04, 1.59472059e-01,\n",
              "       1.25040575e-05, 3.08357649e-02, 2.20844869e-02, 9.74221735e-02,\n",
              "       0.00000000e+00, 0.00000000e+00, 8.25557248e-04, 6.83360736e-02,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.65319533e-02, 0.00000000e+00,\n",
              "       3.77240946e-03, 0.00000000e+00, 0.00000000e+00, 8.24618991e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.52867667e-02, 0.00000000e+00,\n",
              "       7.42921716e-02, 6.56342872e-02, 8.56358078e-03, 1.25711789e-01,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.77899423e-01,\n",
              "       1.69263601e-03, 1.85126219e-02, 1.83214459e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 6.58362631e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       6.01524906e-03, 0.00000000e+00, 1.10047890e-02, 1.12217847e-02,\n",
              "       0.00000000e+00, 4.30460658e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.64769819e-03, 0.00000000e+00, 3.01287798e-03])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Local explainability and masks"
      ],
      "metadata": {
        "id": "F_aaBXHS_IsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explain_matrix, masks = clf.explain(X_test)"
      ],
      "metadata": {
        "id": "iZ23H-Qj_JWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "UhUQAvH8_LAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
        "\n",
        "for i in range(3):\n",
        "    axs[i].imshow(masks[i][:50])\n",
        "    axs[i].set_title(f\"mask {i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "1ZkT0fTM_NSt",
        "outputId": "6f2f3c58-a8a4-4d75-eac5-0495fa5aa851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB"
      ],
      "metadata": {
        "id": "zr8AdL5L_Q8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "clf_xgb = XGBRegressor(max_depth=8,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=1000,\n",
        "    verbosity=0,\n",
        "    silent=None,\n",
        "    objective='reg:linear',\n",
        "    booster='gbtree',\n",
        "    n_jobs=-1,\n",
        "    nthread=None,\n",
        "    gamma=0,\n",
        "    min_child_weight=1,\n",
        "    max_delta_step=0,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=1,\n",
        "    colsample_bylevel=1,\n",
        "    colsample_bynode=1,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=1,\n",
        "    scale_pos_weight=1,\n",
        "    base_score=0.5,\n",
        "    random_state=0,\n",
        "    seed=None,)\n",
        "\n",
        "clf_xgb.fit(X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        early_stopping_rounds=40,\n",
        "        verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYymRQat_Rv9",
        "outputId": "a6d7ed3a-3deb-4447-c397-52f30b518578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:11.5698\n",
            "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
            "[10]\tvalidation_0-rmse:4.22168\n",
            "[20]\tvalidation_0-rmse:1.84508\n",
            "[30]\tvalidation_0-rmse:1.24047\n",
            "[40]\tvalidation_0-rmse:1.13455\n",
            "[50]\tvalidation_0-rmse:1.14045\n",
            "[60]\tvalidation_0-rmse:1.15115\n",
            "[70]\tvalidation_0-rmse:1.15277\n",
            "[80]\tvalidation_0-rmse:1.1607\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-rmse:1.12364\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(max_depth=8, n_estimators=1000, n_jobs=-1, subsample=0.7,\n",
              "             verbosity=0)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.array(clf_xgb.predict(X_valid))\n",
        "valid_auc = mean_squared_error(y_pred=preds, y_true=y_valid)\n",
        "print(valid_auc)\n",
        "\n",
        "preds = np.array(clf_xgb.predict(X_test))\n",
        "test_auc = mean_squared_error(y_pred=preds, y_true=y_test)\n",
        "print(test_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAEAzp9i_UkL",
        "outputId": "419dcb5d-bb37-47c1-c59a-f96ff61361c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.262564741039033\n",
            "2.108831329979667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zh8lFK_g-bgC"
      }
    }
  ]
}