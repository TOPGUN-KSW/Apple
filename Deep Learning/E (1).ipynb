{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFNrmliR4YQq",
        "outputId": "c48d67ef-1b1d-41c2-d23b-cd25c77e7fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tt4hwvcc4eW6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "enV1JcYF4iG1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/Shareddrives/Topgun/dataset/Apple3.csv', encoding='utf-8')\n",
        "sugar = df['SUGAR']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyJIp4Gc4jOR",
        "outputId": "770731e8-7678-4cb3-da5e-0874bf8b16c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<data frame>\n",
            "       apple  imageName label  \\\n",
            "0         1    1-1.JPG  HIGH   \n",
            "1         1    1-2.JPG  HIGH   \n",
            "2         1    1-3.JPG  HIGH   \n",
            "3         1    1-4.JPG  HIGH   \n",
            "4         1    1-5.JPG  HIGH   \n",
            "...     ...        ...   ...   \n",
            "1195    200  200-2.JPG   LOW   \n",
            "1196    200  200-3.JPG   LOW   \n",
            "1197    200  200-4.JPG   LOW   \n",
            "1198    200  200-5.JPG   LOW   \n",
            "1199    200  200-6.JPG   LOW   \n",
            "\n",
            "                                                   path  \n",
            "0     /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "1     /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "2     /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "3     /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "4     /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "...                                                 ...  \n",
            "1195  /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "1196  /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "1197  /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "1198  /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "1199  /content/drive/Shareddrives/Topgun/dataset/tra...  \n",
            "\n",
            "[1200 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "data_dict = { 'apple': [], 'imageName':[], 'label':[], 'path':[]}\n",
        "   \n",
        "for i in range(200):     #0-159\n",
        "  for j in range(1, 7):\n",
        "    filename = str(i+1)+'-'+str(j)+'.JPG'\n",
        "    img_path = '/content/drive/Shareddrives/Topgun/dataset/train'+'/'+filename\n",
        "    data_dict['path'].append(img_path)\n",
        "    data_dict['imageName'].append(filename)\n",
        "    data_dict['label'].append(sugar[i])\n",
        "    data_dict['apple'].append(i+1)\n",
        "  \n",
        "apple_df = pd.DataFrame(data_dict)\n",
        "print('\\n<data frame>\\n', apple_df)\n",
        "    \n",
        "apple_df.to_csv(\"train.csv\", mode='w')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "vFUpM5zL43dg",
        "outputId": "3d9cf344-88d3-4b83-b91d-caf9a64c59ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_df shape: (1200, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   apple imageName label  \\\n",
              "0      1   1-1.JPG  HIGH   \n",
              "1      1   1-2.JPG  HIGH   \n",
              "2      1   1-3.JPG  HIGH   \n",
              "3      1   1-4.JPG  HIGH   \n",
              "4      1   1-5.JPG  HIGH   \n",
              "\n",
              "                                                       path  \n",
              "0  /content/drive/Shareddrives/Topgun/dataset/train/1-1.JPG  \n",
              "1  /content/drive/Shareddrives/Topgun/dataset/train/1-2.JPG  \n",
              "2  /content/drive/Shareddrives/Topgun/dataset/train/1-3.JPG  \n",
              "3  /content/drive/Shareddrives/Topgun/dataset/train/1-4.JPG  \n",
              "4  /content/drive/Shareddrives/Topgun/dataset/train/1-5.JPG  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac29d01d-f38c-4ab3-ad55-c72faf26dd0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>apple</th>\n",
              "      <th>imageName</th>\n",
              "      <th>label</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1-1.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/1-1.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1-2.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/1-2.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1-3.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/1-3.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1-4.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/1-4.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1-5.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/1-5.JPG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac29d01d-f38c-4ab3-ad55-c72faf26dd0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac29d01d-f38c-4ab3-ad55-c72faf26dd0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac29d01d-f38c-4ab3-ad55-c72faf26dd0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "data_df = apple_df\n",
        "print('data_df shape:', data_df.shape)\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO7nsVpC7YTK",
        "outputId": "4697ac39-f1a8-4416-af71-eeb808596d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MEDIUM    546\n",
              "LOW       336\n",
              "HIGH      318\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(data_df.shape)\n",
        "\n",
        "data_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Wh_OsAJ08MHR",
        "outputId": "ccb8aedc-d406-436c-9496-14bfa4907ad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), <a list of 3 Text major ticklabel objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1872x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from ast import increment_lineno\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(26, 4))\n",
        "\n",
        "sns.countplot(data=data_df, x='label')\n",
        "plt.xticks(rotation=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8DwG0g9rVns7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def show_sugar_images(image_path_list, ncols=3, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "28YgjvMQFQkK"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "\n",
        "imsi_augmentor = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.5),\n",
        "    #A.CenterCrop(height=200, width=200, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
        "    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5)\n",
        "])\n",
        "\n",
        "\n",
        "# image size 224x224 resize 적용. \n",
        "def show_sugar_images(image_path_list, augmentor=None, ncols=4, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        if augmentor is not None:\n",
        "            image = augmentor(image=image)['image']\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(title) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v0ozobZWZiq",
        "outputId": "d814726c-d81c-4697-d92e-c8bb92731def"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MEDIUM', 'LOW', 'HIGH']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data_df['label'].value_counts().index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XJJL6uEnWccD"
      },
      "outputs": [],
      "source": [
        "# sugar_list = data_df['label'].value_counts().index.tolist()\n",
        "\n",
        "# for iter_cnt, sugar in enumerate(sugar_list):\n",
        "#     sugar_image_list = data_df[data_df['label']==sugar]['path'].iloc[:6].tolist()\n",
        "#     show_sugar_images(sugar_image_list, ncols=6, title=sugar)\n",
        "#     if iter_cnt == 8:\n",
        "#         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsS1PHndWniB",
        "outputId": "3c7fb7b1-74c4-49bb-fe9f-7f1fba94c69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(960, 4) (240, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.2, stratify=data_df['label'], random_state=2021)\n",
        "print(train_df.shape, test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpcJfs5BeC0S",
        "outputId": "4ed1275a-5081-4b6c-d70a-8f8c8dfdd02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEDIUM    0.455208\n",
            "LOW       0.280208\n",
            "HIGH      0.264583\n",
            "Name: label, dtype: float64\n",
            "MEDIUM    0.454167\n",
            "LOW       0.279167\n",
            "HIGH      0.266667\n",
            "Name: label, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(train_df['label'].value_counts()/train_df.shape[0])\n",
        "print(test_df['label'].value_counts()/test_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9hg9CnqeEa7",
        "outputId": "6df182c7-516f-465c-9402-6b007385ba2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training path shape: (768,) validation path shape: (192,) training label shape: (768, 3) validation label shape: (192, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_path = train_df['path'].values\n",
        "\n",
        "train_label = pd.get_dummies(train_df['label']).values\n",
        " \n",
        "tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, stratify=train_label, test_size=0.2, random_state=0)\n",
        "print('training path shape:', tr_path.shape, 'validation path shape:', val_path.shape, \n",
        "      'training label shape:', tr_label.shape, 'validation label shape:', val_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HofsAyx2eUAU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "class Sugar_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size, self.image_size, 3), dtype='float32')\n",
        "        \n",
        "\n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7kNBgl91WK3"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "\n",
        "augmentor_light = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6VRpGwQ1ppu",
        "outputId": "bb425d89-755e-4897-e6c7-ab192f21cc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 224, 224, 3) (64, 224, 224, 3)\n",
            "[[[[ 0.5137255   0.6392157   0.7647059 ]\n",
            "   [ 0.5294118   0.64705884  0.77254903]\n",
            "   [ 0.49803925  0.62352943  0.7411765 ]\n",
            "   ...\n",
            "   [ 0.6         0.3411765   0.0196079 ]\n",
            "   [ 0.5529412   0.39607847  0.24705887]\n",
            "   [ 0.8980392   0.8666667   0.8745098 ]]\n",
            "\n",
            "  [[ 0.41176474  0.54509807  0.67058825]\n",
            "   [ 0.39607847  0.5294118   0.67058825]\n",
            "   [ 0.32549024  0.45882356  0.6       ]\n",
            "   ...\n",
            "   [ 0.62352943  0.36470592  0.02745104]\n",
            "   [ 0.67058825  0.52156866  0.4039216 ]\n",
            "   [ 0.88235295  0.84313726  0.8745098 ]]\n",
            "\n",
            "  [[ 0.38823533  0.52156866  0.6627451 ]\n",
            "   [ 0.34901965  0.4666667   0.6156863 ]\n",
            "   [ 0.38823533  0.5137255   0.6392157 ]\n",
            "   ...\n",
            "   [ 0.5294118   0.27843142 -0.04313725]\n",
            "   [ 0.75686276  0.6156863   0.49803925]\n",
            "   [ 0.85882354  0.84313726  0.8666667 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.49803925  0.5137255   0.60784316]\n",
            "   [ 0.3803922   0.3803922   0.47450984]\n",
            "   [ 0.36470592  0.35686278  0.4666667 ]\n",
            "   ...\n",
            "   [ 0.827451    0.81960785  0.84313726]\n",
            "   [ 0.8901961   0.8509804   0.88235295]\n",
            "   [ 0.20784318  0.16078436  0.17647064]]\n",
            "\n",
            "  [[ 0.54509807  0.54509807  0.6392157 ]\n",
            "   [ 0.33333337  0.33333337  0.41960788]\n",
            "   [ 0.39607847  0.39607847  0.4901961 ]\n",
            "   ...\n",
            "   [ 0.8352941   0.81960785  0.84313726]\n",
            "   [ 0.9137255   0.88235295  0.8901961 ]\n",
            "   [ 0.18431377  0.13725495  0.15294123]]\n",
            "\n",
            "  [[ 0.41960788  0.41960788  0.5137255 ]\n",
            "   [ 0.5764706   0.5764706   0.67058825]\n",
            "   [ 0.41960788  0.41960788  0.5137255 ]\n",
            "   ...\n",
            "   [ 0.827451    0.8117647   0.8352941 ]\n",
            "   [ 0.8980392   0.85882354  0.8901961 ]\n",
            "   [ 0.20000005  0.15294123  0.14509809]]]]\n",
            "[[[[-0.5529412  -0.6784314  -0.78039217]\n",
            "   [ 0.54509807  0.5058824   0.5372549 ]\n",
            "   [ 0.78039217  0.7647059   0.8039216 ]\n",
            "   ...\n",
            "   [ 0.49803925  0.5921569   0.7019608 ]\n",
            "   [ 0.32549024  0.41960788  0.5058824 ]\n",
            "   [ 0.10588241  0.21568632  0.30196083]]\n",
            "\n",
            "  [[-0.6313726  -0.77254903 -0.88235295]\n",
            "   [ 0.5921569   0.54509807  0.5764706 ]\n",
            "   [ 0.7882353   0.77254903  0.8117647 ]\n",
            "   ...\n",
            "   [ 0.47450984  0.5686275   0.69411767]\n",
            "   [ 0.4901961   0.58431375  0.70980394]\n",
            "   [ 0.32549024  0.41960788  0.54509807]]\n",
            "\n",
            "  [[-0.5921569  -0.73333335 -0.827451  ]\n",
            "   [ 0.5921569   0.54509807  0.5686275 ]\n",
            "   [ 0.79607844  0.78039217  0.81960785]\n",
            "   ...\n",
            "   [ 0.4901961   0.58431375  0.6862745 ]\n",
            "   [ 0.38823533  0.48235297  0.58431375]\n",
            "   [ 0.41960788  0.5137255   0.62352943]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.19999999 -0.36470586 -0.5137255 ]\n",
            "   [-0.38823527 -0.5372549  -0.67058825]\n",
            "   [ 0.4039216   0.36470592  0.4039216 ]\n",
            "   ...\n",
            "   [ 0.48235297  0.49803925  0.6       ]\n",
            "   [ 0.49803925  0.5137255   0.60784316]\n",
            "   [ 0.52156866  0.5372549   0.6313726 ]]\n",
            "\n",
            "  [[-0.19999999 -0.38039213 -0.52156866]\n",
            "   [-0.2862745  -0.46666664 -0.60784316]\n",
            "   [ 0.32549024  0.30196083  0.35686278]\n",
            "   ...\n",
            "   [ 0.4039216   0.41960788  0.5137255 ]\n",
            "   [ 0.47450984  0.47450984  0.5764706 ]\n",
            "   [ 0.5372549   0.56078434  0.654902  ]]\n",
            "\n",
            "  [[-0.17647058 -0.35686272 -0.4980392 ]\n",
            "   [-0.38039213 -0.5529412  -0.7176471 ]\n",
            "   [ 0.2313726   0.2313726   0.30196083]\n",
            "   ...\n",
            "   [ 0.36470592  0.3803922   0.47450984]\n",
            "   [ 0.47450984  0.4901961   0.58431375]\n",
            "   [ 0.41960788  0.427451    0.5294118 ]]]]\n"
          ]
        }
      ],
      "source": [
        "# Xception(Preprocess_input)\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\n",
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                      augmentor=augmentor_light, shuffle=True, pre_func=xcp_preprocess_input)\n",
        "val_ds = Sugar_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                       augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "\n",
        "tr_image_batch = next(iter(tr_ds))[0]\n",
        "val_image_batch = next(iter(val_ds))[0]\n",
        "print(tr_image_batch.shape, val_image_batch.shape)\n",
        "\n",
        "print(tr_image_batch[:1])\n",
        "print(val_image_batch[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "5kFgmlkz2sF9",
        "outputId": "284bdb9c-159c-4a28-ded1-06f9340ad1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.574078798294067\n",
            "142.82031965255737\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-73b29d72f09f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvalue1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    498\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5393c5c47f45>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# import time\n",
        "\n",
        "# tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, augmentor=augmentor_light, shuffle=True, pre_func=xcp_preprocess_input)\n",
        "# val_ds = Sugar_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "\n",
        "# start = time.time()\n",
        "# for value1, value2 in iter(tr_ds):\n",
        "#     end = time.time()\n",
        "#     print(end - start)\n",
        "#     start = end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2Tz9-Uh22br"
      },
      "outputs": [],
      "source": [
        "# Pretrained model\n",
        "# Xception,ResNet50V2, EfficientNetB0, EfficientNetB1\n",
        "\n",
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_model(model_type='xception', in_shape=(224, 224, 3), n_classes=3):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDKgcuTGVafU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/Shareddrives/Topgun/dataset/Apple3.csv', encoding='utf-8')\n",
        "sugar = df['SUGAR']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iyZuzsSE1_C"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "IMAGE_DIR = '/content/drive/Shareddrives/Topgun/dataset/train' \n",
        "\n",
        "def make_sugar_dataframe(image_dir=IMAGE_DIR):\n",
        "    paths = []\n",
        "    label_gubuns = []\n",
        "    for i in range(200):     #0-159\n",
        "      for j in range(1, 7):\n",
        "        filename = str(i+1)+'-'+str(j)+'.JPG'\n",
        "        file_path = '/content/drive/Shareddrives/Topgun/dataset/train'+'/'+filename\n",
        "        paths.append(file_path)\n",
        "        label_gubuns.append(sugar[i])\n",
        "\n",
        "    data_df = pd.DataFrame({'path':paths, 'label':label_gubuns})\n",
        "    return data_df\n",
        "\n",
        "def get_train_valid(train_df, valid_size=0.2, random_state=2021):\n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.get_dummies(train_df['label']).values\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n",
        "    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n",
        "    return tr_path, val_path, tr_label, val_label\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "\n",
        "class Sugar_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size, self.image_size, 3), dtype='float32')\n",
        "        \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "augmentor_light = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwGZA8ZU7H8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835a2cba-e544-4660-882a-2985ef1025f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 2) (480, 2)\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 30\n",
        "\n",
        "def train_model(model_type, train_df, initial_lr=0.001, augmentor=None, input_pre_func=None):\n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Sugar_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "\n",
        "    print('#######', model_type, ' generate and train ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "    \n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    \n",
        "    history = model.fit(tr_ds, epochs=N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                   validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                   callbacks=([rlr_cb, ely_cb]), verbose=1)\n",
        "    \n",
        "    return model, history\n",
        "\n",
        "IMAGE_DIR = '/content/drive/Shareddrives/Topgun/dataset/train' \n",
        "\n",
        "data_df = make_sugar_dataframe(image_dir=IMAGE_DIR)\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.4, stratify=data_df['label'], random_state=2021)\n",
        "print(train_df.shape, test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBD1sVaa7v7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2d41cb-eb79-48e3-ff8d-64eb750a6908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "####### xception  generate and train ########\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "9/9 [==============================] - 1071s 119s/step - loss: 1.0807 - accuracy: 0.4514 - val_loss: 1.1262 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 52s 6s/step - loss: 0.9227 - accuracy: 0.5747 - val_loss: 1.1353 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.7596 - accuracy: 0.6285 - val_loss: 1.0836 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 52s 6s/step - loss: 0.5559 - accuracy: 0.7778 - val_loss: 1.1873 - val_accuracy: 0.4306 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.3735 - accuracy: 0.8594 - val_loss: 1.2682 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.9358\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.2400 - accuracy: 0.9358 - val_loss: 1.5770 - val_accuracy: 0.4653 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 52s 6s/step - loss: 0.1423 - accuracy: 0.9705 - val_loss: 1.5755 - val_accuracy: 0.4514 - lr: 2.0000e-05\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 52s 6s/step - loss: 0.1312 - accuracy: 0.9757 - val_loss: 1.6222 - val_accuracy: 0.4792 - lr: 2.0000e-05\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9809\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "9/9 [==============================] - 52s 6s/step - loss: 0.1063 - accuracy: 0.9809 - val_loss: 1.6467 - val_accuracy: 0.4792 - lr: 2.0000e-05\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.0799 - accuracy: 0.9913 - val_loss: 1.6300 - val_accuracy: 0.4792 - lr: 4.0000e-06\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.0802 - accuracy: 0.9896 - val_loss: 1.6160 - val_accuracy: 0.4792 - lr: 4.0000e-06\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9844\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.0749 - accuracy: 0.9844 - val_loss: 1.6025 - val_accuracy: 0.4861 - lr: 4.0000e-06\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.0716 - accuracy: 0.9931 - val_loss: 1.5878 - val_accuracy: 0.5000 - lr: 8.0000e-07\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "\n",
        "xception_model, xception_history = train_model(model_type='xception', train_df=train_df, initial_lr=0.0001, augmentor=augmentor_light,\n",
        "                             input_pre_func=xcp_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QycsLKyqMH_X"
      },
      "outputs": [],
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "test_df['gt_class'] = np.argmax(test_label, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh9VAHTRMRa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "588eeceb-061f-4e1d-9997-f62c8cc81717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           path   label  \\\n",
              "645  /content/drive/Shareddrives/Topgun/dataset/train/108-4.JPG  MEDIUM   \n",
              "121   /content/drive/Shareddrives/Topgun/dataset/train/21-2.JPG  MEDIUM   \n",
              "473   /content/drive/Shareddrives/Topgun/dataset/train/79-6.JPG     LOW   \n",
              "582   /content/drive/Shareddrives/Topgun/dataset/train/98-1.JPG     LOW   \n",
              "481   /content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG  MEDIUM   \n",
              "\n",
              "     gt_class  \n",
              "645         2  \n",
              "121         2  \n",
              "473         1  \n",
              "582         1  \n",
              "481         2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ffa5c84-0c11-4e47-b76b-7ae5077e3180\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>gt_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/108-4.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/21-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/79-6.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/98-1.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ffa5c84-0c11-4e47-b76b-7ae5077e3180')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ffa5c84-0c11-4e47-b76b-7ae5077e3180 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ffa5c84-0c11-4e47-b76b-7ae5077e3180');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Fg37-eMe8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32820c03-0861-4f80-82de-e44d142a314d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 768s 109s/step - loss: 1.3182 - accuracy: 0.5354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.318227767944336, 0.5354166626930237]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "\n",
        "xception_model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49avGeV1MvAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee4502a-590c-4cb5-b938-bf7294c26e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 34s 4s/step\n"
          ]
        }
      ],
      "source": [
        "predict_result = xception_model.predict(test_ds, steps=int(np.ceil(len(test_label)/BATCH_SIZE)))\n",
        "predict_class = np.argmax(predict_result, axis=1)\n",
        "test_df['xcp_pred_class'] = predict_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hheJ8rGFM3u_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "a2b5a9e3-2577-42dc-9eac-8e0935e78d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           path   label  \\\n",
              "645  /content/drive/Shareddrives/Topgun/dataset/train/108-4.JPG  MEDIUM   \n",
              "121   /content/drive/Shareddrives/Topgun/dataset/train/21-2.JPG  MEDIUM   \n",
              "473   /content/drive/Shareddrives/Topgun/dataset/train/79-6.JPG     LOW   \n",
              "582   /content/drive/Shareddrives/Topgun/dataset/train/98-1.JPG     LOW   \n",
              "481   /content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG  MEDIUM   \n",
              "\n",
              "     gt_class  xcp_pred_class  \n",
              "645         2               2  \n",
              "121         2               2  \n",
              "473         1               1  \n",
              "582         1               1  \n",
              "481         2               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b182999-ea5d-40bd-8010-45de5c6ba193\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>gt_class</th>\n",
              "      <th>xcp_pred_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/108-4.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/21-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/79-6.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/98-1.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b182999-ea5d-40bd-8010-45de5c6ba193')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b182999-ea5d-40bd-8010-45de5c6ba193 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b182999-ea5d-40bd-8010-45de5c6ba193');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-KlT_snM4j_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "71fa8410-8dd7-4232-c329-f2748e556e06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                            path   label  \\\n",
              "481    /content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG  MEDIUM   \n",
              "1199  /content/drive/Shareddrives/Topgun/dataset/train/200-6.JPG     LOW   \n",
              "387    /content/drive/Shareddrives/Topgun/dataset/train/65-4.JPG  MEDIUM   \n",
              "1152  /content/drive/Shareddrives/Topgun/dataset/train/193-1.JPG    HIGH   \n",
              "940   /content/drive/Shareddrives/Topgun/dataset/train/157-5.JPG     LOW   \n",
              "...                                                          ...     ...   \n",
              "798   /content/drive/Shareddrives/Topgun/dataset/train/134-1.JPG  MEDIUM   \n",
              "904   /content/drive/Shareddrives/Topgun/dataset/train/151-5.JPG     LOW   \n",
              "394    /content/drive/Shareddrives/Topgun/dataset/train/66-5.JPG  MEDIUM   \n",
              "177    /content/drive/Shareddrives/Topgun/dataset/train/30-4.JPG    HIGH   \n",
              "983   /content/drive/Shareddrives/Topgun/dataset/train/164-6.JPG  MEDIUM   \n",
              "\n",
              "      gt_class  xcp_pred_class  \n",
              "481          2               1  \n",
              "1199         1               2  \n",
              "387          2               1  \n",
              "1152         0               2  \n",
              "940          1               0  \n",
              "...        ...             ...  \n",
              "798          2               0  \n",
              "904          1               2  \n",
              "394          2               1  \n",
              "177          0               2  \n",
              "983          2               0  \n",
              "\n",
              "[223 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bba72e6-1fdb-4d2a-9ca2-6d56c3e858fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>gt_class</th>\n",
              "      <th>xcp_pred_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/200-6.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/65-4.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1152</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/193-1.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/157-5.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/134-1.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/151-5.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/66-5.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/30-4.JPG</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/164-6.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bba72e6-1fdb-4d2a-9ca2-6d56c3e858fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bba72e6-1fdb-4d2a-9ca2-6d56c3e858fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bba72e6-1fdb-4d2a-9ca2-6d56c3e858fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "test_df[test_df['gt_class'] != test_df['xcp_pred_class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB-n3XBEM5kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0e9e04-bf82-461c-93b3-e5f470fff4d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MEDIUM    107\n",
              "HIGH       72\n",
              "LOW        44\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "test_df[test_df['gt_class'] != test_df['xcp_pred_class']]['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFDf1mWYM7tR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "34bb9c20-5aef-4aac-da5a-a1248ba78e3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb9504b02d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1872x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "plt.figure(figsize=(26, 4))\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "wrong_result_df = test_df[test_df['gt_class'] != test_df['xcp_pred_class']]\n",
        "\n",
        "sns.countplot(data=wrong_result_df, x='label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGhSQ2UM-pn"
      },
      "outputs": [],
      "source": [
        "def show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        if augmentor is not None:\n",
        "            image = augmentor(image=image)['image']\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(title) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBhy4S2dNWTP",
        "outputId": "5cabbf2e-ea94-4617-b0ff-1c0952a9c3b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "####### efficientnetb0  generate and train ########\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "9/9 [==============================] - 66s 6s/step - loss: 1.0880 - accuracy: 0.4271 - val_loss: 1.0443 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.9480 - accuracy: 0.5382 - val_loss: 1.0335 - val_accuracy: 0.4097 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.8546 - accuracy: 0.6267 - val_loss: 1.0486 - val_accuracy: 0.4097 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.7977 - accuracy: 0.6458 - val_loss: 1.0363 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7311 - accuracy: 0.6979\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.7311 - accuracy: 0.6979 - val_loss: 1.0579 - val_accuracy: 0.4514 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6662 - accuracy: 0.7552 - val_loss: 1.0533 - val_accuracy: 0.4514 - lr: 2.0000e-05\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6403 - accuracy: 0.7431 - val_loss: 1.0471 - val_accuracy: 0.4583 - lr: 2.0000e-05\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7604\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6324 - accuracy: 0.7604 - val_loss: 1.0492 - val_accuracy: 0.4583 - lr: 2.0000e-05\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6001 - accuracy: 0.7899 - val_loss: 1.0408 - val_accuracy: 0.4722 - lr: 4.0000e-06\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6213 - accuracy: 0.7691 - val_loss: 1.0327 - val_accuracy: 0.4792 - lr: 4.0000e-06\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6325 - accuracy: 0.7639 - val_loss: 1.0259 - val_accuracy: 0.4792 - lr: 4.0000e-06\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5883 - accuracy: 0.7934 - val_loss: 1.0196 - val_accuracy: 0.4792 - lr: 4.0000e-06\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6089 - accuracy: 0.7795 - val_loss: 1.0116 - val_accuracy: 0.4722 - lr: 4.0000e-06\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6059 - accuracy: 0.7691 - val_loss: 1.0041 - val_accuracy: 0.4861 - lr: 4.0000e-06\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.6155 - accuracy: 0.7760 - val_loss: 0.9968 - val_accuracy: 0.4931 - lr: 4.0000e-06\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5920 - accuracy: 0.7830 - val_loss: 0.9875 - val_accuracy: 0.5208 - lr: 4.0000e-06\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5875 - accuracy: 0.7969 - val_loss: 0.9783 - val_accuracy: 0.5208 - lr: 4.0000e-06\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5865 - accuracy: 0.7812 - val_loss: 0.9706 - val_accuracy: 0.5208 - lr: 4.0000e-06\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5868 - accuracy: 0.7917 - val_loss: 0.9652 - val_accuracy: 0.5139 - lr: 4.0000e-06\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5696 - accuracy: 0.8021 - val_loss: 0.9618 - val_accuracy: 0.5208 - lr: 4.0000e-06\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5779 - accuracy: 0.8108 - val_loss: 0.9579 - val_accuracy: 0.5208 - lr: 4.0000e-06\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5863 - accuracy: 0.7986 - val_loss: 0.9533 - val_accuracy: 0.5278 - lr: 4.0000e-06\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5809 - accuracy: 0.7691 - val_loss: 0.9498 - val_accuracy: 0.5278 - lr: 4.0000e-06\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5629 - accuracy: 0.7847 - val_loss: 0.9471 - val_accuracy: 0.5278 - lr: 4.0000e-06\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 51s 6s/step - loss: 0.5804 - accuracy: 0.7830 - val_loss: 0.9432 - val_accuracy: 0.5278 - lr: 4.0000e-06\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5434 - accuracy: 0.8142 - val_loss: 0.9398 - val_accuracy: 0.5347 - lr: 4.0000e-06\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5578 - accuracy: 0.7934 - val_loss: 0.9379 - val_accuracy: 0.5347 - lr: 4.0000e-06\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5580 - accuracy: 0.8021 - val_loss: 0.9359 - val_accuracy: 0.5417 - lr: 4.0000e-06\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5726 - accuracy: 0.7899 - val_loss: 0.9344 - val_accuracy: 0.5417 - lr: 4.0000e-06\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 50s 6s/step - loss: 0.5560 - accuracy: 0.7934 - val_loss: 0.9333 - val_accuracy: 0.5417 - lr: 4.0000e-06\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "effb0_model_t1, effb0_history_t1 = train_model(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, augmentor=augmentor_light,\n",
        "                             input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2wJof_HNcQw",
        "outputId": "4e81686e-df6f-4531-c24e-881e0297539a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 33s 4s/step - loss: 0.9306 - accuracy: 0.5604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9305852055549622, 0.5604166388511658]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_t1.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUz7lABENhZh",
        "outputId": "1ae12cba-b853-4f61-f1cc-4deba93b81d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 34s 4s/step\n"
          ]
        }
      ],
      "source": [
        "predict_result = effb0_model_t1.predict(test_ds, steps=int(np.ceil(len(test_label)/BATCH_SIZE)))\n",
        "predict_class = np.argmax(predict_result, axis=1)\n",
        "test_df['effb0_t1_pred_class'] = predict_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "OjJjnY9FNjRX",
        "outputId": "a07ebf34-e400-4cc9-c356-7a7db8b9fa3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           path   label  \\\n",
              "645  /content/drive/Shareddrives/Topgun/dataset/train/108-4.JPG  MEDIUM   \n",
              "121   /content/drive/Shareddrives/Topgun/dataset/train/21-2.JPG  MEDIUM   \n",
              "473   /content/drive/Shareddrives/Topgun/dataset/train/79-6.JPG     LOW   \n",
              "582   /content/drive/Shareddrives/Topgun/dataset/train/98-1.JPG     LOW   \n",
              "481   /content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG  MEDIUM   \n",
              "\n",
              "     gt_class  xcp_pred_class  effb0_t1_pred_class  \n",
              "645         2               2                    2  \n",
              "121         2               2                    2  \n",
              "473         1               1                    2  \n",
              "582         1               1                    1  \n",
              "481         2               1                    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63210097-109e-4b95-b92b-6ad9ee9f00f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>gt_class</th>\n",
              "      <th>xcp_pred_class</th>\n",
              "      <th>effb0_t1_pred_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/108-4.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/21-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/79-6.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/98-1.JPG</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>/content/drive/Shareddrives/Topgun/dataset/train/81-2.JPG</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63210097-109e-4b95-b92b-6ad9ee9f00f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63210097-109e-4b95-b92b-6ad9ee9f00f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63210097-109e-4b95-b92b-6ad9ee9f00f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU1sT36vNlM3",
        "outputId": "1ad4a3db-98eb-4a6e-e317-9db856d8b03b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HIGH      78\n",
              "LOW       71\n",
              "MEDIUM    62\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "test_df[test_df['gt_class'] != test_df['effb0_t1_pred_class']]['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srtssStyOwsq"
      },
      "source": [
        "Pretrained 모델 생성\n",
        "\n",
        "*   ResNet50, Xception, EfficientNetB0, EfficientNetB1 등으로 Pretrained 모델을 생성할 수 있는 함수 생성.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHyGyYGCxMvZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import tensorflow as tf\n",
        "\n",
        "# sugar levels classes 종류는 3가지지\n",
        "\n",
        "def create_model(model_type='xception', in_shape=(224, 224, 3), n_classes=3):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H67oE01mP4tC"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "def train_model(model_type, train_df, initial_lr=0.001, augmentor=None, input_pre_func=None):\n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Sugar_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "    print('### train dataset shape:', next(iter(tr_ds))[0].shape)\n",
        "\n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', model_type, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 3번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    \n",
        "    history = model.fit(tr_ds, epochs=N_EPOCHS, steps_per_epoch=tr_path.shape[0]//BATCH_SIZE, \n",
        "                   validation_data=val_ds, validation_steps=val_path.shape[0]//BATCH_SIZE,\n",
        "                   callbacks=([rlr_cb, ely_cb]), verbose=1)\n",
        "    \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKFC5Y9HP7k6"
      },
      "source": [
        "\n",
        "EfficientNetB0 기반에서 Augmentation 기법을 변화 시키면서 모델 학습, ReduceLROnPlateau 적용용\n",
        "\n",
        "*   학습 데이터가 적을 경우 Augmentation이 너무 약할 경우, 과적합(Overfitting), Augmentation이 너무 강하거나 잘못 될 경우 과소적합(Underfitting)이 가능성이 있음.\n",
        "*   이전에 적용한 좌우 반전보다는 더 다양한 기법을 적용하면서 모델 학습하고, 학습 데이터와 검증 데이터의 loss/metric 변화 추이 모니터링.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf19oHqQQf-S"
      },
      "outputs": [],
      "source": [
        "augmentor_heavy_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.CenterCrop(height=90, width=90, p=0.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=1, max_holes=26), \n",
        "         A.CLAHE(p=1),\n",
        "         A.Blur(blur_limit=(10, 15), p=1)\n",
        "        ], p=0.3)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP2IwcSuQkaq",
        "outputId": "66961519-3020-4fa2-e04e-5ea5d50e400a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "### train dataset shape: (64, 224, 224, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "9/9 [==============================] - 71s 7s/step - loss: 1.1189 - accuracy: 0.3733 - val_loss: 1.0930 - val_accuracy: 0.4141 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 1.0187 - accuracy: 0.4878 - val_loss: 1.0678 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9705 - accuracy: 0.5035 - val_loss: 1.0632 - val_accuracy: 0.3906 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9573 - accuracy: 0.5365 - val_loss: 1.0521 - val_accuracy: 0.4141 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9300 - accuracy: 0.5469 - val_loss: 1.0437 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9088 - accuracy: 0.5660 - val_loss: 1.0379 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8708 - accuracy: 0.5608 - val_loss: 1.0389 - val_accuracy: 0.4531 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8329 - accuracy: 0.6024 - val_loss: 1.0501 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8221 - accuracy: 0.5903\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8221 - accuracy: 0.5903 - val_loss: 1.0470 - val_accuracy: 0.4531 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7714 - accuracy: 0.6372 - val_loss: 1.0401 - val_accuracy: 0.4609 - lr: 2.0000e-05\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7836 - accuracy: 0.6424 - val_loss: 1.0345 - val_accuracy: 0.4609 - lr: 2.0000e-05\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7453 - accuracy: 0.6771 - val_loss: 1.0269 - val_accuracy: 0.4531 - lr: 2.0000e-05\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7482 - accuracy: 0.6580 - val_loss: 1.0255 - val_accuracy: 0.4453 - lr: 2.0000e-05\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7670 - accuracy: 0.6510 - val_loss: 1.0125 - val_accuracy: 0.4453 - lr: 2.0000e-05\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7272 - accuracy: 0.6667 - val_loss: 1.0127 - val_accuracy: 0.4609 - lr: 2.0000e-05\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7321 - accuracy: 0.6476 - val_loss: 1.0083 - val_accuracy: 0.4766 - lr: 2.0000e-05\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.7295 - accuracy: 0.6684 - val_loss: 1.0093 - val_accuracy: 0.4453 - lr: 2.0000e-05\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7218 - accuracy: 0.6649 - val_loss: 1.0023 - val_accuracy: 0.4688 - lr: 2.0000e-05\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.7214 - accuracy: 0.6823 - val_loss: 0.9968 - val_accuracy: 0.4766 - lr: 2.0000e-05\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7010 - accuracy: 0.6875 - val_loss: 1.0053 - val_accuracy: 0.4766 - lr: 2.0000e-05\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.7072 - accuracy: 0.6979 - val_loss: 1.0011 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.6823\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7068 - accuracy: 0.6823 - val_loss: 0.9983 - val_accuracy: 0.5078 - lr: 2.0000e-05\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.6746 - accuracy: 0.7205 - val_loss: 0.9946 - val_accuracy: 0.5156 - lr: 4.0000e-06\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.6900 - accuracy: 0.6910 - val_loss: 0.9956 - val_accuracy: 0.5078 - lr: 4.0000e-06\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.7011 - accuracy: 0.6944 - val_loss: 0.9971 - val_accuracy: 0.5078 - lr: 4.0000e-06\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.6753\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.6951 - accuracy: 0.6753 - val_loss: 1.0007 - val_accuracy: 0.5234 - lr: 4.0000e-06\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7030 - accuracy: 0.6840 - val_loss: 0.9997 - val_accuracy: 0.5234 - lr: 8.0000e-07\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.6603 - accuracy: 0.7049 - val_loss: 0.9989 - val_accuracy: 0.5234 - lr: 8.0000e-07\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.6615\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7018 - accuracy: 0.6615 - val_loss: 0.9986 - val_accuracy: 0.5312 - lr: 8.0000e-07\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7100 - accuracy: 0.6753 - val_loss: 0.9992 - val_accuracy: 0.5312 - lr: 1.6000e-07\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "effb0_model_aug01, effb0_history_aug01 = train_model(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                                     augmentor=augmentor_heavy_01, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M69YHf1mQlEb"
      },
      "source": [
        "학습된 모델을 이용하여 테스트 데이터로 Evaluation 및 Prediction 수행."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwTSwE5mQsvx",
        "outputId": "f158f857-3e59-4838-a2d2-15f07cf32c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 33s 4s/step - loss: 0.9367 - accuracy: 0.5813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9367288947105408, 0.581250011920929]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "test_classes = np.argmax(test_label, axis=1)\n",
        "test_df['gt_class'] = test_classes\n",
        "\n",
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_aug01.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiufetZDQu3J",
        "outputId": "53ccf45a-2c88-41db-d9b1-bc9c12d3ff27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 34s 4s/step\n",
            "HIGH      70\n",
            "MEDIUM    69\n",
            "LOW       62\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 테스트 Dataset으로 개별 image들의 predict 수행. \n",
        "predict_result = effb0_model_aug01.predict(test_ds, steps=int(np.ceil(len(test_label)/BATCH_SIZE)))\n",
        "predict_class = np.argmax(predict_result, axis=1)\n",
        "\n",
        "test_df['effb0_aug01_pred_class'] = predict_class\n",
        "print(test_df[test_df['gt_class'] != test_df['effb0_aug01_pred_class']]['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMuyHUqfSeQS"
      },
      "source": [
        "다른 Augmentation을 적용\n",
        "\n",
        "*   CenterCrop을 제외하고 probability를 약간 변경.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kN8TpE4SqRI"
      },
      "outputs": [],
      "source": [
        "augmentor_heavy_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
        "    A.ColorJitter(p=0.3),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=0.3, max_holes=26), \n",
        "         A.CLAHE(p=0.3),\n",
        "         A.Blur(blur_limit=(10, 15), p=0.3)\n",
        "        ], p=0.3)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTayuKvS54h",
        "outputId": "94a01739-901c-4925-99e0-6ac643af1f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "### train dataset shape: (64, 224, 224, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 75s 7s/step - loss: 1.0900 - accuracy: 0.4427 - val_loss: 1.1293 - val_accuracy: 0.3828 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 1.0199 - accuracy: 0.4844 - val_loss: 1.0847 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.9763 - accuracy: 0.5312 - val_loss: 1.0597 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.9214 - accuracy: 0.5434 - val_loss: 1.0664 - val_accuracy: 0.3906 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8657 - accuracy: 0.6024 - val_loss: 1.0642 - val_accuracy: 0.4141 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8654 - accuracy: 0.5816\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8654 - accuracy: 0.5816 - val_loss: 1.0863 - val_accuracy: 0.3984 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8661 - accuracy: 0.5972 - val_loss: 1.0705 - val_accuracy: 0.4219 - lr: 2.0000e-05\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.8317 - accuracy: 0.6233 - val_loss: 1.0526 - val_accuracy: 0.4453 - lr: 2.0000e-05\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8258 - accuracy: 0.6111 - val_loss: 1.0318 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.8176 - accuracy: 0.6250 - val_loss: 1.0180 - val_accuracy: 0.5078 - lr: 2.0000e-05\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.8272 - accuracy: 0.6146 - val_loss: 1.0152 - val_accuracy: 0.5156 - lr: 2.0000e-05\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7837 - accuracy: 0.6580 - val_loss: 1.0073 - val_accuracy: 0.5312 - lr: 2.0000e-05\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7621 - accuracy: 0.6667 - val_loss: 1.0055 - val_accuracy: 0.5469 - lr: 2.0000e-05\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7840 - accuracy: 0.6528 - val_loss: 1.0072 - val_accuracy: 0.5156 - lr: 2.0000e-05\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7602 - accuracy: 0.6840 - val_loss: 0.9970 - val_accuracy: 0.5156 - lr: 2.0000e-05\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7569 - accuracy: 0.6771 - val_loss: 0.9834 - val_accuracy: 0.5156 - lr: 2.0000e-05\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7771 - accuracy: 0.6302 - val_loss: 0.9734 - val_accuracy: 0.5078 - lr: 2.0000e-05\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7508 - accuracy: 0.6701 - val_loss: 0.9719 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7327 - accuracy: 0.6875 - val_loss: 0.9738 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7489 - accuracy: 0.6840 - val_loss: 0.9777 - val_accuracy: 0.4922 - lr: 2.0000e-05\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7408 - accuracy: 0.6701\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7408 - accuracy: 0.6701 - val_loss: 0.9761 - val_accuracy: 0.5078 - lr: 2.0000e-05\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7095 - accuracy: 0.6875 - val_loss: 0.9746 - val_accuracy: 0.5156 - lr: 4.0000e-06\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7286 - accuracy: 0.6649 - val_loss: 0.9736 - val_accuracy: 0.5234 - lr: 4.0000e-06\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.7083\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7057 - accuracy: 0.7083 - val_loss: 0.9739 - val_accuracy: 0.5234 - lr: 4.0000e-06\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.6946 - accuracy: 0.7083 - val_loss: 0.9738 - val_accuracy: 0.5234 - lr: 8.0000e-07\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7289 - accuracy: 0.6701 - val_loss: 0.9736 - val_accuracy: 0.5312 - lr: 8.0000e-07\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7414 - accuracy: 0.6927\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7414 - accuracy: 0.6927 - val_loss: 0.9740 - val_accuracy: 0.5234 - lr: 8.0000e-07\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7382 - accuracy: 0.6684 - val_loss: 0.9739 - val_accuracy: 0.5234 - lr: 1.6000e-07\n",
            "Epoch 28: early stopping\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "effb0_model_aug02, effb0_history_aug02 = train_model(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001,\n",
        "                                               augmentor=augmentor_heavy_02, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjzFB3CaS7Yx",
        "outputId": "7ec781db-7251-4c2c-a0a5-8ac4ad1e4829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "### train dataset shape: (64, 224, 224, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 75s 7s/step - loss: 1.1122 - accuracy: 0.3542 - val_loss: 1.2397 - val_accuracy: 0.2344 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 1.0212 - accuracy: 0.4757 - val_loss: 1.2310 - val_accuracy: 0.2734 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.9752 - accuracy: 0.5087 - val_loss: 1.2157 - val_accuracy: 0.2812 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.9147 - accuracy: 0.5677 - val_loss: 1.1736 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8891 - accuracy: 0.5625 - val_loss: 1.1942 - val_accuracy: 0.3516 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8748 - accuracy: 0.5903 - val_loss: 1.1861 - val_accuracy: 0.3906 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.6215\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.8270 - accuracy: 0.6215 - val_loss: 1.2083 - val_accuracy: 0.3984 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.8014 - accuracy: 0.6267 - val_loss: 1.1771 - val_accuracy: 0.4141 - lr: 2.0000e-05\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7954 - accuracy: 0.6337 - val_loss: 1.1390 - val_accuracy: 0.4297 - lr: 2.0000e-05\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7883 - accuracy: 0.6719 - val_loss: 1.1131 - val_accuracy: 0.4297 - lr: 2.0000e-05\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7787 - accuracy: 0.6580 - val_loss: 1.0929 - val_accuracy: 0.4609 - lr: 2.0000e-05\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.8032 - accuracy: 0.6424 - val_loss: 1.0776 - val_accuracy: 0.4609 - lr: 2.0000e-05\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7595 - accuracy: 0.6528 - val_loss: 1.0648 - val_accuracy: 0.4688 - lr: 2.0000e-05\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7690 - accuracy: 0.6597 - val_loss: 1.0439 - val_accuracy: 0.4688 - lr: 2.0000e-05\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7672 - accuracy: 0.6597 - val_loss: 1.0334 - val_accuracy: 0.4922 - lr: 2.0000e-05\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7365 - accuracy: 0.6823 - val_loss: 1.0222 - val_accuracy: 0.4922 - lr: 2.0000e-05\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7307 - accuracy: 0.6632 - val_loss: 1.0117 - val_accuracy: 0.5078 - lr: 2.0000e-05\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7176 - accuracy: 0.6927 - val_loss: 1.0074 - val_accuracy: 0.5078 - lr: 2.0000e-05\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.6938 - accuracy: 0.7153 - val_loss: 1.0080 - val_accuracy: 0.4922 - lr: 2.0000e-05\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7154 - accuracy: 0.7135 - val_loss: 1.0093 - val_accuracy: 0.4844 - lr: 2.0000e-05\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.7257\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.6699 - accuracy: 0.7257 - val_loss: 1.0184 - val_accuracy: 0.4844 - lr: 2.0000e-05\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7224 - accuracy: 0.6910 - val_loss: 1.0156 - val_accuracy: 0.4922 - lr: 4.0000e-06\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7014 - accuracy: 0.6823 - val_loss: 1.0138 - val_accuracy: 0.4922 - lr: 4.0000e-06\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.6962\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.7007 - accuracy: 0.6962 - val_loss: 1.0101 - val_accuracy: 0.4922 - lr: 4.0000e-06\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7292 - accuracy: 0.6753 - val_loss: 1.0081 - val_accuracy: 0.5078 - lr: 8.0000e-07\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7069 - accuracy: 0.6892 - val_loss: 1.0065 - val_accuracy: 0.5078 - lr: 8.0000e-07\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7045 - accuracy: 0.6701 - val_loss: 1.0053 - val_accuracy: 0.5156 - lr: 8.0000e-07\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7266 - accuracy: 0.6649 - val_loss: 1.0030 - val_accuracy: 0.5156 - lr: 8.0000e-07\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.6952 - accuracy: 0.7049 - val_loss: 1.0015 - val_accuracy: 0.5156 - lr: 8.0000e-07\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.6949 - accuracy: 0.7049 - val_loss: 1.0011 - val_accuracy: 0.5156 - lr: 8.0000e-07\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "effb0_model_aug02, effb0_history_aug02 = train_model(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001,\n",
        "                                               augmentor=augmentor_heavy_02, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "\n",
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_aug02.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "0b8GnwxJeD5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YefKrg1DS8Py"
      },
      "source": [
        "Learning Rate Scheduler를 Ramp Up and Step Decay 방식으로 변경경\n",
        "\n",
        "*   최초는 1e-5에서 2회 Ramp up 단계를 거쳐서, Max인 1e-4까지 증가 시킴, 이후는 Step Decay 방시긍로 2회 마다 learning rate을 줄임\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m_Rl8o0TWMI"
      },
      "outputs": [],
      "source": [
        "# learning rate scheduler에 적용할 함수 선언. 내포 함수를 사용. \n",
        "def lrfn(epoch):\n",
        "    # 내포 함수인 calc_fn()에서 사용되는 파라미터. \n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 2\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    # 반드시 내포 함수인 calc_fn(epoch)를 호출해야함. \n",
        "    return calc_fn(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvgcrrLtTZKP",
        "outputId": "58592f9a-7396-4982-83b5-18510a049dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.5e-05\n",
            "0.0001\n",
            "0.0001\n",
            "0.0001\n",
            "0.0001\n",
            "7.500000000000001e-05\n",
            "7.500000000000001e-05\n",
            "5.6250000000000005e-05\n",
            "5.6250000000000005e-05\n",
            "4.21875e-05\n",
            "4.21875e-05\n",
            "3.1640625e-05\n",
            "3.1640625e-05\n",
            "2.3730468750000002e-05\n",
            "2.3730468750000002e-05\n",
            "1.77978515625e-05\n",
            "1.77978515625e-05\n",
            "1.3348388671875e-05\n",
            "1.3348388671875e-05\n",
            "1.001129150390625e-05\n",
            "1.001129150390625e-05\n",
            "7.508468627929688e-06\n",
            "7.508468627929688e-06\n",
            "5.631351470947266e-06\n",
            "5.631351470947266e-06\n",
            "4.223513603210449e-06\n",
            "4.223513603210449e-06\n",
            "3.167635202407837e-06\n",
            "3.167635202407837e-06\n",
            "2.3757264018058777e-06\n"
          ]
        }
      ],
      "source": [
        "for i in range(30):\n",
        "    print(lrfn(i+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAUvkrsCTx1R"
      },
      "source": [
        "기존 train_model()에 RampUp and Step Decay를 Callback으로 반영할 수 있도록 train_model_with_aug_lr()로 함수 수정\n",
        "\n",
        "*   Learnining Rate Scheduler등의 Callback 객체를 인자로 입력 받을 수 있도록 함수 수정."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQiEMw94UIIy"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "def train_model_with_aug_lr(model_type, train_df, initial_lr=0.001, augmentor=None, callbacks_list=None, input_pre_func=None):\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Sugar_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "\n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', model_type, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # learning rate scheduler와 early stopping 을 함수 인자로 입력 받음. \n",
        "    history = model.fit(tr_ds, epochs=N_EPOCHS, steps_per_epoch=tr_path.shape[0]//BATCH_SIZE, \n",
        "                   validation_data=val_ds, validation_steps=val_path.shape[0]//BATCH_SIZE,\n",
        "                   callbacks=(callbacks_list), verbose=1)\n",
        "    \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx8gCxEwUNZ5",
        "outputId": "1daea03e-6054-4e8d-c33c-a6d8f72c8e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 71s 7s/step - loss: 1.1924 - accuracy: 0.2951 - val_loss: 1.0895 - val_accuracy: 0.3672 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.1095 - accuracy: 0.3837 - val_loss: 1.0841 - val_accuracy: 0.3906 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0574 - accuracy: 0.4253 - val_loss: 1.0869 - val_accuracy: 0.3906 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9873 - accuracy: 0.5000 - val_loss: 1.0367 - val_accuracy: 0.3672 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9671 - accuracy: 0.5260 - val_loss: 1.0049 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9438 - accuracy: 0.5521 - val_loss: 1.0283 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9008 - accuracy: 0.5816 - val_loss: 1.0272 - val_accuracy: 0.4141 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8844 - accuracy: 0.5868 - val_loss: 1.0412 - val_accuracy: 0.4297 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8806 - accuracy: 0.5868 - val_loss: 1.0166 - val_accuracy: 0.4688 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8295 - accuracy: 0.6233 - val_loss: 0.9739 - val_accuracy: 0.4688 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8500 - accuracy: 0.5955 - val_loss: 0.9680 - val_accuracy: 0.4609 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8308 - accuracy: 0.6215 - val_loss: 0.9655 - val_accuracy: 0.4609 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8279 - accuracy: 0.6128 - val_loss: 0.9661 - val_accuracy: 0.4766 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7585 - accuracy: 0.6667 - val_loss: 0.9589 - val_accuracy: 0.4531 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.7905 - accuracy: 0.6163 - val_loss: 0.9520 - val_accuracy: 0.5000 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7782 - accuracy: 0.6615 - val_loss: 0.9492 - val_accuracy: 0.4922 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7580 - accuracy: 0.6510 - val_loss: 0.9520 - val_accuracy: 0.4922 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7592 - accuracy: 0.6701 - val_loss: 0.9553 - val_accuracy: 0.4844 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7523 - accuracy: 0.6476 - val_loss: 0.9595 - val_accuracy: 0.4609 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7583 - accuracy: 0.6510 - val_loss: 0.9630 - val_accuracy: 0.5000 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7588 - accuracy: 0.6615 - val_loss: 0.9651 - val_accuracy: 0.5000 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.7564 - accuracy: 0.6476 - val_loss: 0.9674 - val_accuracy: 0.5234 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7490 - accuracy: 0.6615 - val_loss: 0.9714 - val_accuracy: 0.5156 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7497 - accuracy: 0.6545 - val_loss: 0.9765 - val_accuracy: 0.5234 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7315 - accuracy: 0.6441 - val_loss: 0.9777 - val_accuracy: 0.5234 - lr: 5.6314e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.7480 - accuracy: 0.6753 - val_loss: 0.9781 - val_accuracy: 0.5312 - lr: 5.6314e-06\n",
            "Epoch 26: early stopping\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# Learning Rate Scheduler(Ramp up and step down decay) 와 Early Stopping callback 생성. \n",
        "lr_cb = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "# train_model에 인자로 넣을 Callback 객체의 리스트 생성. \n",
        "callbacks_list = [lr_cb, ely_cb]\n",
        "\n",
        "augmentor_heavy_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.CenterCrop(height=90, width=90, p=0.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=1, max_holes=26), \n",
        "         A.CLAHE(p=1),\n",
        "         A.Blur(blur_limit=(10, 15), p=1)\n",
        "        ], p=0.3)\n",
        "])\n",
        "\n",
        "augmentor_heavy_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
        "    A.ColorJitter(p=0.3),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=0.3, max_holes=26), \n",
        "         A.CLAHE(p=0.3),\n",
        "         A.Blur(blur_limit=(10, 15), p=0.3)\n",
        "        ], p=0.3)\n",
        "])\n",
        "\n",
        "# augmentor_heavy_01을 ramp up and step decay 적용. \n",
        "effb0_model_lr01, effb0_history_lr01 = train_model_with_aug_lr(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                               augmentor=augmentor_heavy_01, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7kQoxVFUOZR",
        "outputId": "26c73867-aba3-412c-f04b-8be7d13753b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 33s 4s/step - loss: 0.9345 - accuracy: 0.5729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9345054030418396, 0.5729166865348816]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_lr01.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqoNApMRUPeh",
        "outputId": "0237bb6c-1489-401e-9d36-8963c48a3ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 74s 7s/step - loss: 1.2127 - accuracy: 0.2969 - val_loss: 1.1620 - val_accuracy: 0.3672 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 1.1216 - accuracy: 0.3889 - val_loss: 1.1093 - val_accuracy: 0.3594 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 1.0520 - accuracy: 0.4497 - val_loss: 1.1052 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 1.0047 - accuracy: 0.4983 - val_loss: 1.0520 - val_accuracy: 0.3828 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.9595 - accuracy: 0.5347 - val_loss: 1.0398 - val_accuracy: 0.4609 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.9444 - accuracy: 0.5087 - val_loss: 1.0116 - val_accuracy: 0.4609 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8980 - accuracy: 0.5781 - val_loss: 1.0109 - val_accuracy: 0.4297 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8640 - accuracy: 0.5938 - val_loss: 1.0112 - val_accuracy: 0.4219 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8498 - accuracy: 0.6042 - val_loss: 0.9980 - val_accuracy: 0.4609 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8245 - accuracy: 0.5955 - val_loss: 0.9917 - val_accuracy: 0.5078 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.8076 - accuracy: 0.6372 - val_loss: 0.9883 - val_accuracy: 0.5156 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7753 - accuracy: 0.6615 - val_loss: 0.9744 - val_accuracy: 0.4922 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7717 - accuracy: 0.6649 - val_loss: 0.9611 - val_accuracy: 0.4844 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7747 - accuracy: 0.6476 - val_loss: 0.9561 - val_accuracy: 0.4844 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7440 - accuracy: 0.6858 - val_loss: 0.9532 - val_accuracy: 0.4922 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7401 - accuracy: 0.6649 - val_loss: 0.9531 - val_accuracy: 0.5156 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7349 - accuracy: 0.6910 - val_loss: 0.9579 - val_accuracy: 0.5156 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7374 - accuracy: 0.6701 - val_loss: 0.9564 - val_accuracy: 0.5156 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7168 - accuracy: 0.7014 - val_loss: 0.9624 - val_accuracy: 0.5156 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7389 - accuracy: 0.6719 - val_loss: 0.9602 - val_accuracy: 0.5156 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7027 - accuracy: 0.6944 - val_loss: 0.9605 - val_accuracy: 0.5156 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7191 - accuracy: 0.6962 - val_loss: 0.9631 - val_accuracy: 0.5078 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.7147 - accuracy: 0.6875 - val_loss: 0.9623 - val_accuracy: 0.5156 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.6902 - accuracy: 0.6910 - val_loss: 0.9642 - val_accuracy: 0.5234 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.6873 - accuracy: 0.7118 - val_loss: 0.9664 - val_accuracy: 0.5156 - lr: 5.6314e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 59s 7s/step - loss: 0.7057 - accuracy: 0.6927 - val_loss: 0.9685 - val_accuracy: 0.5156 - lr: 5.6314e-06\n",
            "Epoch 26: early stopping\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# augmentor_heavy_02를 ramp up and step decay 적용. \n",
        "effb0_model_lr02, effb0_history_lr02 = train_model_with_aug_lr(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                               augmentor=augmentor_heavy_02, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXr89cxoURBx",
        "outputId": "54b72919-df35-42aa-ca76-2d7330839c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 33s 4s/step - loss: 0.8965 - accuracy: 0.5833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8965483903884888, 0.5833333134651184]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_lr02.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lun_zdLjUaPo"
      },
      "source": [
        "Pretrained 모델의 Fine Tuning 적용용\n",
        "\n",
        "*   Fine tuning으로 1차 dense layer 부터 학습 적용, 2차 전체 Layer 학습 적용용\n",
        "*   EfficientNet의 경우는 Batch Normalization은 학습하지 않도록 설정.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A08Mbm9kUw_h",
        "outputId": "947c1c35-1544-4688-f6c3-287bc5e93328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling_6 (Rescaling)        (None, 224, 224, 3)  0           ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " normalization_6 (Normalization  (None, 224, 224, 3)  7          ['rescaling_6[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.truediv_6 (TFOpLambda)  (None, 224, 224, 3)  0          ['normalization_6[0][0]']        \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['tf.math.truediv_6[0][0]']      \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
            "                                )                                 'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
            "                                                                  'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
            "                                                                  'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
            "                                                                  'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
            "                                                                  'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
            "                                                                  'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
            "                                                                  'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
            "                                                                  'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_7 (Gl  (None, 1280)        0           ['top_activation[0][0]']         \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 1024)         1311744     ['global_average_pooling2d_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 1024)         0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 3)            3075        ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,364,390\n",
            "Trainable params: 5,322,367\n",
            "Non-trainable params: 42,023\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_imsi =create_model(model_type='efficientnetb0')\n",
        "model_imsi.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdbHsyo4UyHa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "def train_model_with_ft(model_type, train_df, initial_lr=0.0001, augmentor=None, callbacks_list=None, input_pre_func=None):\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "\n",
        "    tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Sugar_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "\n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', model_type, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    \n",
        "    # Feature Extractor layer들을 모두 Freeze\n",
        "    for layer in model.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    #cosine_decay = tf.keras.experimental.CosineDecay(initial_learning_rate=0.001, decay_steps=300)\n",
        "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "    \n",
        "    ### Feature Extractor layer들은 학습하지 않고 Dense Layer만 일차 학습. \n",
        "    print('##### Feature Extractor freeze후 Dense layer 학습 시작 ##### ')\n",
        "    history = model.fit(tr_ds, epochs=15, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                  validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                  callbacks=(callbacks_list), verbose=1)\n",
        "    # efficientNet의 일부만 trainable 가능하게 설정. 특히 BatchNormalization layer는 trainable False로 유지. \n",
        "    # https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
        "    #for layer in model.layers[-20:]:\n",
        "    for layer in model.layers:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "    \n",
        "    print('##### 전체 Layer Unfreeze 후 학습 시작 ##### ')\n",
        "    history = model.fit(tr_ds, epochs=25, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                  validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                  callbacks=(callbacks_list), verbose=1)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxoa0-EwU1dQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# learning rate scheduler에 적용할 함수 선언. 내포 함수를 사용. \n",
        "def lrfn(epoch):\n",
        "    # 내포 함수인 calc_fn()에서 사용되는 파라미터. \n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    # 반드시 내포 함수인 calc_fn(epoch)를 호출해야함. \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "# Learning Rate Scheduler(Ramp up and step down decay) 와 Early Stopping callback 생성. \n",
        "lr_cb = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "# train_model에 인자로 넣을 Callback 객체의 리스트 생성. \n",
        "callbacks_list = [lr_cb, ely_cb]\n",
        "\n",
        "\n",
        "augmentor_light_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])\n",
        "\n",
        "augmentor_light_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.2, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2)\n",
        "])\n",
        "\n",
        "augmentor_heavy_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.CenterCrop(height=90, width=90, p=0.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=1, max_holes=26), \n",
        "         A.CLAHE(p=1),\n",
        "         A.Blur(blur_limit=(10, 15), p=1)\n",
        "        ], p=0.3)\n",
        "])\n",
        "\n",
        "augmentor_heavy_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
        "    A.ColorJitter(p=0.3),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=0.3, max_holes=26), \n",
        "         A.CLAHE(p=0.3),\n",
        "         A.Blur(blur_limit=(10, 15), p=0.3)\n",
        "        ], p=0.3)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3rf93LGU7Fq",
        "outputId": "bdd6507a-3e3e-463f-fa69-2fc8df872eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n",
            "##### Feature Extractor freeze후 Dense layer 학습 시작 ##### \n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n",
            "9/9 [==============================] - 68s 7s/step - loss: 1.1788 - accuracy: 0.3194 - val_loss: 1.1099 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 1.1421 - accuracy: 0.4028 - val_loss: 1.0994 - val_accuracy: 0.4444 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.1032 - accuracy: 0.4410 - val_loss: 1.0196 - val_accuracy: 0.4306 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0533 - accuracy: 0.4288 - val_loss: 0.9997 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0650 - accuracy: 0.4566 - val_loss: 1.0083 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0428 - accuracy: 0.4479 - val_loss: 0.9845 - val_accuracy: 0.4097 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0228 - accuracy: 0.4601 - val_loss: 0.9780 - val_accuracy: 0.4375 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9958 - accuracy: 0.5052 - val_loss: 0.9839 - val_accuracy: 0.4444 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 57s 6s/step - loss: 1.0118 - accuracy: 0.4774 - val_loss: 0.9762 - val_accuracy: 0.4514 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9794 - accuracy: 0.4878 - val_loss: 0.9712 - val_accuracy: 0.4514 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0027 - accuracy: 0.4722 - val_loss: 0.9673 - val_accuracy: 0.4514 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9662 - accuracy: 0.5156 - val_loss: 0.9663 - val_accuracy: 0.4444 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9983 - accuracy: 0.4844 - val_loss: 0.9665 - val_accuracy: 0.4375 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9875 - accuracy: 0.5000 - val_loss: 0.9642 - val_accuracy: 0.4444 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.0063 - accuracy: 0.4965 - val_loss: 0.9607 - val_accuracy: 0.4722 - lr: 2.3730e-05\n",
            "##### 전체 Layer Unfreeze 후 학습 시작 ##### \n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/25\n",
            "9/9 [==============================] - 61s 7s/step - loss: 0.9787 - accuracy: 0.5174 - val_loss: 0.9604 - val_accuracy: 0.4653 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9899 - accuracy: 0.4878 - val_loss: 0.9645 - val_accuracy: 0.4375 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9894 - accuracy: 0.4965 - val_loss: 0.9483 - val_accuracy: 0.4861 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9737 - accuracy: 0.5104 - val_loss: 0.9445 - val_accuracy: 0.4861 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9449 - accuracy: 0.5382 - val_loss: 0.9482 - val_accuracy: 0.4792 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 6/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9753 - accuracy: 0.5208 - val_loss: 0.9517 - val_accuracy: 0.4722 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9719 - accuracy: 0.5017 - val_loss: 0.9405 - val_accuracy: 0.4583 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 8/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9563 - accuracy: 0.5069 - val_loss: 0.9360 - val_accuracy: 0.4514 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9223 - accuracy: 0.5538 - val_loss: 0.9390 - val_accuracy: 0.4583 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 10/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9615 - accuracy: 0.5174 - val_loss: 0.9420 - val_accuracy: 0.4653 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9506 - accuracy: 0.5260 - val_loss: 0.9411 - val_accuracy: 0.4792 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 12/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9541 - accuracy: 0.5365 - val_loss: 0.9390 - val_accuracy: 0.4583 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9397 - accuracy: 0.5469 - val_loss: 0.9396 - val_accuracy: 0.4514 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 14/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9533 - accuracy: 0.5208 - val_loss: 0.9373 - val_accuracy: 0.4514 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9555 - accuracy: 0.5208 - val_loss: 0.9360 - val_accuracy: 0.4375 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 16/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9429 - accuracy: 0.5312 - val_loss: 0.9344 - val_accuracy: 0.4375 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 17/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9269 - accuracy: 0.5556 - val_loss: 0.9339 - val_accuracy: 0.4583 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 18/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9314 - accuracy: 0.5590 - val_loss: 0.9336 - val_accuracy: 0.4722 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 19/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9361 - accuracy: 0.5694 - val_loss: 0.9335 - val_accuracy: 0.4514 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 20/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9233 - accuracy: 0.5382 - val_loss: 0.9338 - val_accuracy: 0.4514 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 21/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9397 - accuracy: 0.5434 - val_loss: 0.9340 - val_accuracy: 0.4583 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 22/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9287 - accuracy: 0.5503 - val_loss: 0.9338 - val_accuracy: 0.4653 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 23/25\n",
            "9/9 [==============================] - 57s 6s/step - loss: 0.9291 - accuracy: 0.5312 - val_loss: 0.9337 - val_accuracy: 0.4653 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 24/25\n",
            "9/9 [==============================] - 58s 7s/step - loss: 0.9452 - accuracy: 0.5208 - val_loss: 0.9336 - val_accuracy: 0.4792 - lr: 5.6314e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 25/25\n",
            "9/9 [==============================] - 57s 7s/step - loss: 0.9471 - accuracy: 0.5139 - val_loss: 0.9333 - val_accuracy: 0.4792 - lr: 5.6314e-06\n"
          ]
        }
      ],
      "source": [
        "effb0_model_ft01, effb0_history_ft01 = train_model_with_ft(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                            augmentor=augmentor_heavy_01, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r497VFQ4U8XZ",
        "outputId": "68cb74fa-0174-4dac-de1c-1ae2e6ff1e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 34s 4s/step - loss: 0.9441 - accuracy: 0.5292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.944101870059967, 0.5291666388511658]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_ft01.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9TboJ_GU-DR"
      },
      "source": [
        "lighter한 Augmentation 적용용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siOj2K28VDGI",
        "outputId": "79e45233-02ce-4803-a7c2-58e6e7d1dbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (576,) tr_label shape: (576, 3) val_path shape: (144,) val_label shape: (144, 3)\n",
            "####### efficientnetb0  생성 및 학습 수행 ########\n",
            "##### Feature Extractor freeze후 Dense layer 학습 시작 ##### \n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n",
            "9/9 [==============================] - 68s 7s/step - loss: 1.1769 - accuracy: 0.3611 - val_loss: 1.0922 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 56s 6s/step - loss: 1.1141 - accuracy: 0.3941 - val_loss: 1.0834 - val_accuracy: 0.4444 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 1.0720 - accuracy: 0.4688 - val_loss: 0.9986 - val_accuracy: 0.4653 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 1.0171 - accuracy: 0.4635 - val_loss: 0.9912 - val_accuracy: 0.4653 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 1.0098 - accuracy: 0.4809 - val_loss: 0.9820 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9871 - accuracy: 0.5069 - val_loss: 0.9686 - val_accuracy: 0.5139 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9768 - accuracy: 0.5017 - val_loss: 0.9752 - val_accuracy: 0.4514 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9703 - accuracy: 0.5017 - val_loss: 0.9679 - val_accuracy: 0.4722 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9833 - accuracy: 0.4896 - val_loss: 0.9595 - val_accuracy: 0.4861 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9643 - accuracy: 0.5208 - val_loss: 0.9612 - val_accuracy: 0.4722 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9612 - accuracy: 0.5243 - val_loss: 0.9552 - val_accuracy: 0.4792 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9541 - accuracy: 0.5434 - val_loss: 0.9543 - val_accuracy: 0.4792 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9513 - accuracy: 0.5191 - val_loss: 0.9532 - val_accuracy: 0.4792 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9253 - accuracy: 0.5382 - val_loss: 0.9521 - val_accuracy: 0.4722 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9521 - accuracy: 0.5399 - val_loss: 0.9503 - val_accuracy: 0.5000 - lr: 2.3730e-05\n",
            "##### 전체 Layer Unfreeze 후 학습 시작 ##### \n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/25\n",
            "9/9 [==============================] - 60s 7s/step - loss: 0.9339 - accuracy: 0.5347 - val_loss: 0.9504 - val_accuracy: 0.4861 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9563 - accuracy: 0.5104 - val_loss: 0.9477 - val_accuracy: 0.5139 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9626 - accuracy: 0.5069 - val_loss: 0.9474 - val_accuracy: 0.4861 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/25\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9334 - accuracy: 0.5226 - val_loss: 0.9422 - val_accuracy: 0.4931 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9323 - accuracy: 0.5451 - val_loss: 0.9357 - val_accuracy: 0.4861 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 6/25\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.9341 - accuracy: 0.5260 - val_loss: 0.9311 - val_accuracy: 0.4722 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9185 - accuracy: 0.5486 - val_loss: 0.9318 - val_accuracy: 0.5139 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 8/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8995 - accuracy: 0.5608 - val_loss: 0.9335 - val_accuracy: 0.5069 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9044 - accuracy: 0.5712 - val_loss: 0.9241 - val_accuracy: 0.5069 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 10/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8894 - accuracy: 0.5972 - val_loss: 0.9254 - val_accuracy: 0.5139 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9197 - accuracy: 0.5486 - val_loss: 0.9279 - val_accuracy: 0.5069 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 12/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9070 - accuracy: 0.5590 - val_loss: 0.9273 - val_accuracy: 0.5139 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/25\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8934 - accuracy: 0.5781 - val_loss: 0.9231 - val_accuracy: 0.5139 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 14/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8848 - accuracy: 0.5799 - val_loss: 0.9217 - val_accuracy: 0.5139 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9073 - accuracy: 0.5660 - val_loss: 0.9205 - val_accuracy: 0.5278 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 16/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8698 - accuracy: 0.5885 - val_loss: 0.9216 - val_accuracy: 0.5208 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1.77978515625e-05.\n",
            "Epoch 17/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8832 - accuracy: 0.5955 - val_loss: 0.9196 - val_accuracy: 0.5208 - lr: 1.7798e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 18/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8721 - accuracy: 0.6024 - val_loss: 0.9188 - val_accuracy: 0.5208 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1.3348388671875e-05.\n",
            "Epoch 19/25\n",
            "9/9 [==============================] - 56s 6s/step - loss: 0.8908 - accuracy: 0.5660 - val_loss: 0.9175 - val_accuracy: 0.5278 - lr: 1.3348e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 20/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8861 - accuracy: 0.5747 - val_loss: 0.9169 - val_accuracy: 0.5208 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1.001129150390625e-05.\n",
            "Epoch 21/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8865 - accuracy: 0.5885 - val_loss: 0.9167 - val_accuracy: 0.5139 - lr: 1.0011e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 22/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9075 - accuracy: 0.5642 - val_loss: 0.9157 - val_accuracy: 0.5208 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 7.508468627929688e-06.\n",
            "Epoch 23/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8811 - accuracy: 0.5955 - val_loss: 0.9155 - val_accuracy: 0.5208 - lr: 7.5085e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 24/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.9077 - accuracy: 0.5625 - val_loss: 0.9154 - val_accuracy: 0.5208 - lr: 5.6314e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 5.631351470947266e-06.\n",
            "Epoch 25/25\n",
            "9/9 [==============================] - 55s 6s/step - loss: 0.8758 - accuracy: 0.5990 - val_loss: 0.9155 - val_accuracy: 0.5208 - lr: 5.6314e-06\n"
          ]
        }
      ],
      "source": [
        "effb0_model_ft02, effb0_history_ft02 = train_model_with_ft(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                            augmentor=augmentor_light_02, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcQNAeFVVFRn",
        "outputId": "7c88d0c7-ef35-4313-bbaf-f3ed8b88b78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 34s 4s/step - loss: 0.9262 - accuracy: 0.5479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9262027144432068, 0.5479166507720947]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "test_ds = Sugar_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_ft02.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4M26xxlVHYY"
      },
      "source": [
        "지금까지 변경 테스트한 여러 환경들을 손쉽게 테스트 해볼 수 있도록 함수 재구성\n",
        "\n",
        "*   Config 클래스를 만들어서 여기에 테스트에 필요한 인자들을 모두 설정 할 수 있도록 함.\n",
        "*   train_model()인자로 Config를 입력 받아서 이를 기반으로 학습을 수행할 수 있도록 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CCfrG5qpVbgB"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    MODEL_TYPE = 'effcientnetb0'\n",
        "    IMAGE_SIZE = 224\n",
        "    BATCH_SIZE = 64\n",
        "    N_EPOCHS = 30 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False # Fine Tuning 여부\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 25 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = None # 모델 train시 적용될 callback 객체들의 List\n",
        "    SECOND_CALLBACKS = None # 만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = None\n",
        "    PRE_FUNC = None\n",
        "    INITIAL_LR = 0.0001 # Optimizer에 적용될 최초 Learning rate\n",
        "    DEBUG = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chi4DM5vVkLf"
      },
      "source": [
        "아래는 기존에 사용한 라이브러리 함수 그대로 가져온 것것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uXpn0xDDVnIa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import tensorflow as tf\n",
        "\n",
        "# LOW MEDIUM HIGH : Classes 3개개\n",
        "N_CLASSES = 3\n",
        "\n",
        "def create_model(model_type='xception', in_shape=(224, 224, 3), n_classes=3):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb2':\n",
        "        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb3':\n",
        "        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "IMAGE_DIR = '/content/drive/Shareddrives/Topgun/dataset/train' \n",
        "\n",
        "def make_sugar_dataframe(image_dir=IMAGE_DIR):\n",
        "    paths = []\n",
        "    label_gubuns = []\n",
        "    for i in range(200):     #0-159\n",
        "      for j in range(1, 7):\n",
        "        filename = str(i+1)+'-'+str(j)+'.JPG'\n",
        "        file_path = '/content/drive/Shareddrives/Topgun/dataset/train'+'/'+filename\n",
        "        paths.append(file_path)\n",
        "        label_gubuns.append(sugar[i])\n",
        "\n",
        "    data_df = pd.DataFrame({'path':paths, 'label':label_gubuns})\n",
        "    return data_df\n",
        "\n",
        "def get_train_valid(train_df, valid_size=0.2, random_state=2021):\n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.get_dummies(train_df['label']).values\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n",
        "    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n",
        "    return tr_path, val_path, tr_label, val_label\n",
        "\n",
        "    \n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "\n",
        "class Sugar_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
        "    def __getitem__(self, index):\n",
        "        # index는 몇번째 batch인지를 나타냄. \n",
        "        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # image_batch 배열은 float32 로 설정. \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size, self.image_size, 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            #crop 시 잘린 이미지가 원본 이미지와 다르게 되므로 augmentation 적용 후 resize() 적용. \n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "            # 만일 preprocessing_input이 pre_func인자로 들어오면 이를 이용하여 scaling 적용. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 전체 image 파일의 위치와 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "augmentor_light = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])"
      ],
      "metadata": {
        "id": "fKhYAwnU_zzy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBHgaeQFWUlv"
      },
      "source": [
        "train_model 함수를 Config 클래스 값을 인자로 입력 받을 수 있도록 변경경"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_df, config=Config):\n",
        "    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Sugar_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n",
        "    val_ds = Sugar_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "    if config.DEBUG:\n",
        "        tr_image_batch = next(iter(tr_ds))[0]\n",
        "        val_image_batch = next(iter(val_ds))[0]\n",
        "        print(tr_image_batch.shape, val_image_batch.shape)\n",
        "        print(tr_image_batch[0], val_image_batch[0])\n",
        "        \n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE, config.IMAGE_SIZE, 3), n_classes=3)\n",
        "    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    # 만일 Fine tuning 일 경우 아래 로직 적용. \n",
        "    if config.IS_FINE_TUNING:\n",
        "        print('####### Fine tuning 학습을 시작합니다. ########')\n",
        "        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n",
        "        for layer in model.layers[:-4]:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        print('####### Classification Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "        # # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. Batch Normalization layer는 fine tuning시 계속 trainable=False 설정. \n",
        "        # for layer in model.layers:\n",
        "        #     print(layer)\n",
        "        #     if not isinstance(layer, layers.BatchNormalization):\n",
        "        #         layer.trainable = True\n",
        "        \n",
        "        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n",
        "    \n",
        "    # Fine Tuning이 아닐 경우 \n",
        "    else:\n",
        "        print('####### 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "    return model, history"
      ],
      "metadata": {
        "id": "WaiJP093_5th"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB1 모델 학습 및 성능 평가\n",
        "\n",
        "\n",
        "*   Config 클래스의 내부 변수값으로 할당 될 수 있도록 Learning Rate Scheduler에 적용될 함수, Callback 객체, Augmentation 객체들을 생성성\n",
        "*   EfficientNetB1의 경우 240X240 이미지 크기로 최적화 되었으므로 이에 맞게 Config 값 설정."
      ],
      "metadata": {
        "id": "eZVAcXGX_-8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cIk_La_CXBc-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# learning rate scheduler에 적용할 함수 선언. \n",
        "def lrfn_01(epoch):\n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "def lrfn_02(epoch):\n",
        "    LR_START = 1e-6\n",
        "    LR_MAX = 2e-5\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "# Config에 입력할 callback 생성. \n",
        "lr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\n",
        "lr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "\n",
        "# Augmentor 생성. \n",
        "\n",
        "augmentor_light_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.2, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2)\n",
        "])\n",
        "\n",
        "# Config 생성. \n",
        "class Config:\n",
        "    MODEL_TYPE = 'efficientnetb1'\n",
        "    IMAGE_SIZE = 240\n",
        "    BATCH_SIZE = 64\n",
        "    N_EPOCHS = 30 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = True\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_light_02\n",
        "    PRE_FUNC = eff_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB1 모델 학습"
      ],
      "metadata": {
        "id": "V06BqgJxAY90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiDvGDGUXGfo",
        "outputId": "ecfb2345-38b0-455a-ddd3-484fb2306c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr_path shape: (768,) tr_label shape: (768, 3) val_path shape: (192,) val_label shape: (192, 3)\n",
            "####### efficientnetb1  생성 및 학습 수행 ########\n",
            "####### Fine tuning 학습을 시작합니다. ########\n",
            "####### Classification Layer들의 학습을 시작합니다. ########\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n",
            "12/12 [==============================] - 95s 7s/step - loss: 1.1177 - accuracy: 0.3672 - val_loss: 1.1058 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.5e-05.\n",
            "Epoch 2/15\n",
            "12/12 [==============================] - 75s 6s/step - loss: 1.0872 - accuracy: 0.4271 - val_loss: 1.0499 - val_accuracy: 0.4583 - lr: 5.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 1.0023 - accuracy: 0.4831 - val_loss: 1.0106 - val_accuracy: 0.5104 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.9377 - accuracy: 0.5091 - val_loss: 0.9786 - val_accuracy: 0.5104 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.8647 - accuracy: 0.5768 - val_loss: 0.9601 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 6/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.8304 - accuracy: 0.6198 - val_loss: 0.9498 - val_accuracy: 0.5260 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
            "Epoch 7/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.7882 - accuracy: 0.6536 - val_loss: 0.9547 - val_accuracy: 0.5365 - lr: 7.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 8/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.7656 - accuracy: 0.6628 - val_loss: 0.9409 - val_accuracy: 0.5521 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 5.6250000000000005e-05.\n",
            "Epoch 9/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.7264 - accuracy: 0.6797 - val_loss: 0.9127 - val_accuracy: 0.5417 - lr: 5.6250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 10/15\n",
            "12/12 [==============================] - 75s 6s/step - loss: 0.7243 - accuracy: 0.6745 - val_loss: 0.8924 - val_accuracy: 0.5469 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.21875e-05.\n",
            "Epoch 11/15\n",
            "12/12 [==============================] - 75s 6s/step - loss: 0.7109 - accuracy: 0.6719 - val_loss: 0.8609 - val_accuracy: 0.5625 - lr: 4.2188e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 12/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.6515 - accuracy: 0.7240 - val_loss: 0.8446 - val_accuracy: 0.5781 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 3.1640625e-05.\n",
            "Epoch 13/15\n",
            "12/12 [==============================] - 75s 6s/step - loss: 0.6377 - accuracy: 0.7083 - val_loss: 0.8536 - val_accuracy: 0.5833 - lr: 3.1641e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 14/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.6414 - accuracy: 0.7331 - val_loss: 0.8445 - val_accuracy: 0.5938 - lr: 2.3730e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.3730468750000002e-05.\n",
            "Epoch 15/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.6098 - accuracy: 0.7526 - val_loss: 0.8377 - val_accuracy: 0.5885 - lr: 2.3730e-05\n",
            "####### 전체 Layer들의 학습을 시작합니다. ########\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 1/15\n",
            "12/12 [==============================] - 78s 7s/step - loss: 0.5868 - accuracy: 0.7565 - val_loss: 0.8267 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 1.0500000000000001e-05.\n",
            "Epoch 2/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.5964 - accuracy: 0.7435 - val_loss: 0.8109 - val_accuracy: 0.6562 - lr: 1.0500e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 3/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.5918 - accuracy: 0.7708 - val_loss: 0.8108 - val_accuracy: 0.6562 - lr: 2.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 4/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.5722 - accuracy: 0.7643 - val_loss: 0.7931 - val_accuracy: 0.6719 - lr: 2.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 5/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.5970 - accuracy: 0.7448 - val_loss: 0.7948 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 1.5000000000000002e-05.\n",
            "Epoch 6/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.5590 - accuracy: 0.7643 - val_loss: 0.7905 - val_accuracy: 0.6875 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 1.5000000000000002e-05.\n",
            "Epoch 7/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.5198 - accuracy: 0.8086 - val_loss: 0.7936 - val_accuracy: 0.6823 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 1.125e-05.\n",
            "Epoch 8/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.5534 - accuracy: 0.7695 - val_loss: 0.7969 - val_accuracy: 0.6823 - lr: 1.1250e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 1.125e-05.\n",
            "Epoch 9/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.5111 - accuracy: 0.7982 - val_loss: 0.7978 - val_accuracy: 0.6875 - lr: 1.1250e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 8.4375e-06.\n",
            "Epoch 10/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.5097 - accuracy: 0.7917 - val_loss: 0.8015 - val_accuracy: 0.6979 - lr: 8.4375e-06\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.4375e-06.\n",
            "Epoch 11/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.5222 - accuracy: 0.8008 - val_loss: 0.8019 - val_accuracy: 0.7031 - lr: 8.4375e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 6.3281250000000005e-06.\n",
            "Epoch 12/15\n",
            "12/12 [==============================] - 74s 6s/step - loss: 0.5074 - accuracy: 0.8073 - val_loss: 0.7999 - val_accuracy: 0.6979 - lr: 6.3281e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 6.3281250000000005e-06.\n",
            "Epoch 13/15\n",
            "12/12 [==============================] - 73s 6s/step - loss: 0.5175 - accuracy: 0.7826 - val_loss: 0.7970 - val_accuracy: 0.7083 - lr: 6.3281e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 4.746093750000001e-06.\n",
            "Epoch 14/15\n",
            "12/12 [==============================] - 72s 6s/step - loss: 0.4863 - accuracy: 0.8099 - val_loss: 0.7966 - val_accuracy: 0.6979 - lr: 4.7461e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 4.746093750000001e-06.\n",
            "Epoch 15/15\n",
            "12/12 [==============================] - 72s 6s/step - loss: 0.4882 - accuracy: 0.8125 - val_loss: 0.7986 - val_accuracy: 0.6927 - lr: 4.7461e-06\n"
          ]
        }
      ],
      "source": [
        "eff1_model, history = train_model(train_df, config=Config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8GLBiyNtXGz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac694dbb-01ee-4150-9af4-f78a86f2cea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 17s 4s/step - loss: 0.9283 - accuracy: 0.5667\n",
            "evaluation_result: [0.9282916784286499, 0.5666666626930237]\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, test_df, config=Config):\n",
        "    test_path = test_df['path'].values\n",
        "    test_label = pd.get_dummies(test_df['label']).values\n",
        "    test_ds = Sugar_Dataset(test_path, test_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "\n",
        "    evaluation_result = model.evaluate(test_ds)\n",
        "    print('evaluation_result:', evaluation_result)\n",
        "    \n",
        "    return model, evaluation_result\n",
        "\n",
        "model, evaluation_result = evaluate_model(model=eff1_model, test_df=test_df, config=Config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KA7fUqhLuO6Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}